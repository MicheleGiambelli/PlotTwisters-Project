{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMR9jALk+KynKge8wW301Vt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5544d84f152647c2b0f7946f240b75fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3fec287400d4562af1af91b89bdf0e0",
              "IPY_MODEL_368f08f61d284843a1eefe2338fb7c70",
              "IPY_MODEL_6887f77fdbdf4a35b0c542b5c02b245f"
            ],
            "layout": "IPY_MODEL_86f6b882500049adbfe1f86bbffd320e"
          }
        },
        "a3fec287400d4562af1af91b89bdf0e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e414f89527634fb8b45669b819f3fa97",
            "placeholder": "​",
            "style": "IPY_MODEL_95d88877e3804fe2a1c69c83d2ac13b9",
            "value": "Map: 100%"
          }
        },
        "368f08f61d284843a1eefe2338fb7c70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52d6d72201e04189943da2fffe4022de",
            "max": 2993,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06d56aa960a54a89830fdbfee3a78fc5",
            "value": 2993
          }
        },
        "6887f77fdbdf4a35b0c542b5c02b245f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_099a545b0ee6424f9fce3ab355a2193c",
            "placeholder": "​",
            "style": "IPY_MODEL_c830868a43a34873a022e2c1b90c318f",
            "value": " 2993/2993 [00:00&lt;00:00, 3261.58 examples/s]"
          }
        },
        "86f6b882500049adbfe1f86bbffd320e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e414f89527634fb8b45669b819f3fa97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95d88877e3804fe2a1c69c83d2ac13b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52d6d72201e04189943da2fffe4022de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06d56aa960a54a89830fdbfee3a78fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "099a545b0ee6424f9fce3ab355a2193c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c830868a43a34873a022e2c1b90c318f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "868f7cec01e74024bce5fbbd38a1edcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d10e93e040c34eceb7d656994be5c11c",
              "IPY_MODEL_c9779042eb484859a2fdbe3a1844d507",
              "IPY_MODEL_89b07317607c4224873c15c0fd8fdbdc"
            ],
            "layout": "IPY_MODEL_dc70f35c0b8b4d15ab38ddc20025523a"
          }
        },
        "d10e93e040c34eceb7d656994be5c11c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa09777f3b95403ca32dc70eccf1ac85",
            "placeholder": "​",
            "style": "IPY_MODEL_b76a42fcc3f44da6bfb9fefae7753761",
            "value": "Map: 100%"
          }
        },
        "c9779042eb484859a2fdbe3a1844d507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_818cad9b12c54ca991f5cd366bf2f098",
            "max": 855,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6ab131801e04aeda1f9e97472714abe",
            "value": 855
          }
        },
        "89b07317607c4224873c15c0fd8fdbdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80e5f7a3855d427ca1153836e896cfd7",
            "placeholder": "​",
            "style": "IPY_MODEL_268bda9d5c484e8a8dcf919db2e183f5",
            "value": " 855/855 [00:00&lt;00:00, 2892.23 examples/s]"
          }
        },
        "dc70f35c0b8b4d15ab38ddc20025523a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa09777f3b95403ca32dc70eccf1ac85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b76a42fcc3f44da6bfb9fefae7753761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "818cad9b12c54ca991f5cd366bf2f098": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6ab131801e04aeda1f9e97472714abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80e5f7a3855d427ca1153836e896cfd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "268bda9d5c484e8a8dcf919db2e183f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf4711960499438fba4b601a1e1bf81e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4fd362f52c23483e986d5dc5527abd1e",
              "IPY_MODEL_3cde5a8b0d8d4654ae7a692457a19252",
              "IPY_MODEL_d59fd3ec62214d8d970e00a4b5e11731"
            ],
            "layout": "IPY_MODEL_0b1474a958ce4faaa052a82b362ddea5"
          }
        },
        "4fd362f52c23483e986d5dc5527abd1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf1b2872a96f4288a90d29b704a1acb0",
            "placeholder": "​",
            "style": "IPY_MODEL_b3cbfd510251430c86400dac75e103f8",
            "value": "Map: 100%"
          }
        },
        "3cde5a8b0d8d4654ae7a692457a19252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b24b1bbb39f548ce87753f1f7602f9ac",
            "max": 428,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c4fde4b6a7e46baad27ce13ae911059",
            "value": 428
          }
        },
        "d59fd3ec62214d8d970e00a4b5e11731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_803b0d60d08a460b84297c891cb3a36d",
            "placeholder": "​",
            "style": "IPY_MODEL_b9d9ce70f97f4f2299233e8aba07fcd5",
            "value": " 428/428 [00:00&lt;00:00, 2626.76 examples/s]"
          }
        },
        "0b1474a958ce4faaa052a82b362ddea5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf1b2872a96f4288a90d29b704a1acb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3cbfd510251430c86400dac75e103f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b24b1bbb39f548ce87753f1f7602f9ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c4fde4b6a7e46baad27ce13ae911059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "803b0d60d08a460b84297c891cb3a36d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9d9ce70f97f4f2299233e8aba07fcd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MicheleGiambelli/PlotTwisters-Project/blob/main/Transformer_funzionante_emma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "!pip install transformers datasets evaluate\n",
        "!pip install transformers datasets evaluate seqeval\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification, pipeline\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from datasets import Dataset, DatasetDict\n",
        "import evaluate\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import spacy\n",
        "from collections import Counter, defaultdict\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import plotly.express as px\n",
        "import networkx as nx\n",
        "from PIL import Image\n",
        "import random\n",
        "from itertools import combinations\n",
        "from scipy.interpolate import make_interp_spline\n",
        "from numpy.random import seed\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "M2OQAw6jtPOJ",
        "outputId": "d576ad24-5d41-4348-95c7-1465b2f577e4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.5.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df1 = pd.read_csv('sample_data/file5.txt', header=None, delimiter='\\t', names=['token', 'ner_tag'], skip_blank_lines=False)\n",
        "# df1[\"token\"] = df1[\"token\"].fillna(\"end\")\n",
        "# df1[\"ner_tag\"] = df1[\"ner_tag\"].fillna(\"end\")\n",
        "\n",
        "# df2 = pd.read_csv('sample_data/file6.txt', header=None, delimiter='\\t', names=['token', 'ner_tag'], skip_blank_lines=False)\n",
        "# df2[\"token\"] = df2[\"token\"].fillna(\"end\")\n",
        "# df2[\"ner_tag\"] = df2[\"ner_tag\"].fillna(\"end\")\n",
        "\n",
        "\n",
        "def file_to_dataframe(file_path):\n",
        "    data = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()  # Leggi tutte le righe del file\n",
        "        for i, line in enumerate(lines):\n",
        "            line = line.strip()  # Rimuove spazi e newline extra\n",
        "            if not line:  # Linea vuota, segna come fine frase\n",
        "                data.append((\"end\", \"end\"))\n",
        "                continue\n",
        "\n",
        "            # Controlla se la riga contiene '\\t' per separare token e tag\n",
        "            if '\\t' in line:\n",
        "                parts = line.split('\\t')\n",
        "                if len(parts) == 2:  # La riga è valida con 2 parti\n",
        "                    token, ner_tag = parts\n",
        "                    data.append((token, ner_tag))\n",
        "                else:  # Riga malformata\n",
        "                    print(f\"Riga malformata alla linea {i + 1}: {line}\")\n",
        "            else:  # Riga senza '\\t'\n",
        "                print(f\"Riga senza tabulazione alla linea {i + 1}: {line}\")\n",
        "                # data.append((\"end\", \"end\"))\n",
        "\n",
        "    return pd.DataFrame(data, columns=['token', 'ner_tag'])\n",
        "\n",
        "# Converti entrambi i file in DataFrame\n",
        "df1 = file_to_dataframe('sample_data/file5.txt')\n",
        "df2 = file_to_dataframe('sample_data/file5.txt')\n",
        "\n",
        "\n",
        "#Assegna id di frase a file6\n",
        "sentence_id = 0\n",
        "for idx, row in df1.iterrows():\n",
        "  df1.loc[idx, 'id'] = sentence_id\n",
        "  if row['token'] == 'end' and row[\"ner_tag\"]==\"end\":\n",
        "    sentence_id += 1\n",
        "\n",
        "for idx, row in df2.iterrows():\n",
        "  df2.loc[idx, 'id'] = sentence_id\n",
        "  if row['token'] == 'end' and row[\"ner_tag\"]==\"end\":\n",
        "    sentence_id += 1\n",
        "\n",
        "\n",
        "df1 = df1[df1[\"ner_tag\"] != \"end\"]\n",
        "df2 = df2[df2[\"ner_tag\"] != \"end\"]\n",
        "\n",
        "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "# Convertire la colonna id da float a int\n",
        "combined_df['id'] = combined_df['id'].astype(int)\n",
        "\n",
        "\n",
        "combined_df = combined_df.dropna(subset=['token']).reset_index(drop=True) # con questo medodo possiamo rimuovere le righe del dataframe il cui valore è mancante\n",
        "\n",
        "# Verifichiamo la presenza di righe vuote (serve più avanti per un problema al codice altrimenti)\n",
        "invalid_tokens = combined_df[~combined_df['token'].apply(lambda x: isinstance(x, str))]\n",
        "\n",
        "# Eliminare le righe con valori non stringa nella colonna 'token'\n",
        "combined_df = combined_df[combined_df['token'].apply(lambda x: isinstance(x, str))].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "kVwwBzpcxTbc"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def file_to_dataframe(file_path):\n",
        "    data = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()  # Leggi tutte le righe del file\n",
        "        for i, line in enumerate(lines):\n",
        "            line = line.strip()  # Rimuove spazi e newline extra\n",
        "            if not line:  # Linea vuota, segna come fine frase\n",
        "                data.append((\"end\", \"end\"))\n",
        "                continue\n",
        "\n",
        "            # Controlla se la riga contiene '\\t' per separare token e tag\n",
        "            if '\\t' in line:\n",
        "                parts = line.split('\\t')\n",
        "                if len(parts) == 2:  # La riga è valida con 2 parti\n",
        "                    token, ner_tag = parts\n",
        "                    data.append((token, ner_tag))\n",
        "                else:  # Riga malformata\n",
        "                    print(f\"Riga malformata alla linea {i + 1}: {line}\")\n",
        "            else:  # Riga senza '\\t'\n",
        "                print(f\"Riga senza tabulazione alla linea {i + 1}: {line}\")\n",
        "                data.append((\"end\", \"end\"))\n",
        "\n",
        "    return pd.DataFrame(data, columns=['token', 'ner_tag'])\n",
        "\n"
      ],
      "metadata": {
        "id": "uzw5F7G4xi21"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "QuRYwbRmtEds"
      },
      "outputs": [],
      "source": [
        "# Combinare i dataset\n",
        "combined_df = pd.concat([df1, df2]).reset_index(drop=True)\n",
        "\n",
        "# Caricare il modello di lingua inglese\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "stopwords = nlp.Defaults.stop_words\n",
        "# Punteggiatura da rimuovere\n",
        "punctuation = set(string.punctuation) - {'@'}\n",
        "\n",
        "# Funzione per eliminare stopwords e punteggiatura\n",
        "def remove_stopwords_and_punctuation(df):\n",
        "    df['token_cleaned'] = df['token'].apply(lambda x: x if x.lower() not in stopwords and x not in punctuation else '')\n",
        "    df = df[df['token_cleaned'] != '']  # Rimuove le righe con token vuoti\n",
        "    return df.drop(columns=['token']).rename(columns={'token_cleaned': 'token'})\n",
        "\n",
        "# Applicare la funzione al dataset combinato\n",
        "combined_df = remove_stopwords_and_punctuation(combined_df)\n",
        "\n",
        "# Elimina le righe in cui il token è \"rt\"\n",
        "combined_df = combined_df[combined_df['token'] != 'rt']\n",
        "\n",
        "# Reset dell'indice per un DataFrame pulito\n",
        "combined_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Rimuovere eventuali NaN o valori non stringa\n",
        "combined_df = combined_df.dropna(subset=['token']).reset_index(drop=True)\n",
        "combined_df = combined_df[combined_df['token'].apply(lambda x: isinstance(x, str))].reset_index(drop=True)\n",
        "\n",
        "# Dividere il dataset in train, validation e test\n",
        "unique_ids = combined_df['id'].unique()\n",
        "seed(42)\n",
        "shuffled_ids = pd.Series(unique_ids).sample(frac=1, random_state=42).values\n",
        "train_ids, temp_ids = train_test_split(shuffled_ids, test_size=0.3, random_state=42)\n",
        "val_ids, test_ids = train_test_split(temp_ids, test_size=1/3, random_state=42)\n",
        "train_df = combined_df[combined_df['id'].isin(train_ids)]\n",
        "val_df = combined_df[combined_df['id'].isin(val_ids)]\n",
        "test_df = combined_df[combined_df['id'].isin(test_ids)]\n",
        "\n",
        "# Mappare le etichette NER a ID unici\n",
        "all_df = pd.concat([train_df, val_df, test_df])\n",
        "unique_tags = all_df['ner_tag'].unique().tolist()\n",
        "tag2id = {tag: idx for idx, tag in enumerate(unique_tags)}\n",
        "id2tag = {idx: tag for tag, idx in tag2id.items()}\n",
        "train_df['ner_tag_id'] = train_df['ner_tag'].map(tag2id)\n",
        "val_df['ner_tag_id'] = val_df['ner_tag'].map(tag2id)\n",
        "test_df['ner_tag_id'] = test_df['ner_tag'].map(tag2id)\n",
        "\n",
        "save_directory = r'C:\\Users\\capel\\OneDrive\\Desktop\\Data Visualization and Text Mining\\Assignment\\best_ner_model'\n",
        "\n",
        "# Crea la directory se non esiste\n",
        "if not os.path.exists(save_directory):\n",
        "    os.makedirs(save_directory)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***distilbert-base-cased***\n",
        "\n",
        "Di seguito ho utilizzato un modello già attestrato chiamato ***distilbert-base-cased***.\n",
        "\n",
        "Cos'è *distilbert-base-cased*:\n",
        "\n",
        "*DistilBERT* è una versione più leggera e veloce di *BERT* (Bidirectional Encoder Representations from Transformers).                                      \n",
        "Creato da *Hugging Face*, *DistilBERT* è stato ottenuto attraverso una tecnica chiamata distillazione del modello, che permette di comprimere un modello più grande (come BERT) in uno più piccolo mantenendo gran parte delle sue prestazioni.                                                                     \n",
        "Il modello distilbert-base-cased è la versione di DistilBERT che distingue tra maiuscole e minuscole (case-sensitive). Ciò significa che tratta le parole \"Apple\" e \"apple\" come token diversi.\n",
        "Caratteristiche principali:\n",
        "\n",
        "                                                                                     \n",
        "Dimensioni ridotte:\n",
        "\n",
        "DistilBERT ha circa il 40% in meno di parametri rispetto a BERT base.\n",
        "Questo lo rende più leggero e più veloce da addestrare e inferire.\n",
        "\n",
        "\n",
        "Prestazioni:\n",
        "\n",
        "Nonostante sia più piccolo, DistilBERT mantiene circa il 97% delle prestazioni di BERT su diversi benchmark NLP.\n",
        "\n",
        "\n",
        "Vantaggi:\n",
        "\n",
        "- Efficienza computazionale: Richiede meno memoria e risorse computazionali.\n",
        "- Velocità: Più veloce sia durante l'addestramento che durante l'inferenza.\n",
        "- Adatto per ambienti con risorse limitate: Ideale per applicazioni che necessitano di modelli leggeri.\n",
        "\n",
        "\n",
        "Quando utilizzare distilbert-base-cased:\n",
        "\n",
        "Quando hai limitazioni di risorse (RAM, GPU).\n",
        "Se hai bisogno di addestrare o eseguire inferenze rapidamente.\n",
        "Quando il leggero calo di prestazioni rispetto a BERT è accettabile per il tuo caso d'uso.\n",
        "\n",
        "\n",
        "Link utili:\n",
        "\n",
        "Modello su Hugging Face: Puoi trovare più informazioni su distilbert-base-cased sulla pagina ufficiale del modello su Hugging Face: https://huggingface.co/distilbert-base-cased\n",
        "\n",
        "\n",
        "Paper originale: Se sei interessato alla tecnica di distillazione, puoi leggere il paper originale: \"DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter\""
      ],
      "metadata": {
        "id": "tPdeqkMYCohK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Disabilitare wandb per evitare richieste di API key\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"   # Disabilitare wandb (Weights and Biases): evita richieste di autenticazione a Weights and Biases, uno strumento di monitoraggio delle esperienze di machine learning.\n",
        "\n",
        "\n",
        "save_directory = r'C:\\Users\\capel\\OneDrive\\Desktop\\Data Visualization and Text Mining\\Assignment'\n",
        "\n",
        "# Creare la directory se non esiste\n",
        "if not os.path.exists(save_directory):\n",
        "    os.makedirs(save_directory)\n",
        "\n",
        "# **Passo 1: Mappare le etichette NER a ID unici**\n",
        "\n",
        "\n",
        "all_df = pd.concat([train_df, val_df, test_df])\n",
        "# Creare mapping tra tag NER e ID\n",
        "unique_tags = all_df['ner_tag'].unique().tolist()\n",
        "tag2id = {tag: idx for idx, tag in enumerate(unique_tags)}\n",
        "id2tag = {idx: tag for tag, idx in tag2id.items()}\n",
        "\n",
        "# Convertire 'ner_tag' in 'ner_tag_id' per ciascun DataFrame\n",
        "train_df['ner_tag_id'] = train_df['ner_tag'].map(tag2id)\n",
        "val_df['ner_tag_id'] = val_df['ner_tag'].map(tag2id)\n",
        "test_df['ner_tag_id'] = test_df['ner_tag'].map(tag2id)\n",
        "\n",
        "\n",
        "\n",
        "# **Passo 2: Preparare i dati per Hugging Face**\n",
        "\n",
        "# Raggruppare i token e le etichette per frase utilizzando 'id' come identificatore\n",
        "def group_data(df):\n",
        "    return df.groupby('id').agg({'token': list, 'ner_tag_id': list}).reset_index()  # raggruppa i token e le etichette per frase utilizzando id come identificatore unico\n",
        "\n",
        "train_dataset = group_data(train_df)\n",
        "val_dataset = group_data(val_df)\n",
        "test_dataset = group_data(test_df)\n",
        "\n",
        "\n",
        "\n",
        "# **Passo 3: Verificare l'allineamento tra token e etichette**\n",
        "\n",
        "def check_token_label_alignment(df_grouped):\n",
        "    misaligned = df_grouped[\n",
        "        df_grouped['token'].str.len() != df_grouped['ner_tag_id'].str.len()\n",
        "    ]\n",
        "    if not misaligned.empty:\n",
        "        print(\"Frasi con disallineamento tra token e etichette:\")\n",
        "        print(misaligned)\n",
        "    return misaligned.empty\n",
        "\n",
        "assert check_token_label_alignment(train_dataset), \"Disallineamento tra token e etichette nel train set\"\n",
        "assert check_token_label_alignment(val_dataset), \"Disallineamento tra token e etichette nel validation set\"\n",
        "assert check_token_label_alignment(test_dataset), \"Disallineamento tra token e etichette nel test set\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# **Passo 4: Creare i dataset per Hugging Face**\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_dataset)\n",
        "val_dataset = Dataset.from_pandas(val_dataset)\n",
        "test_dataset = Dataset.from_pandas(test_dataset)\n",
        "\n",
        "datasets = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'validation': val_dataset,\n",
        "    'test': test_dataset\n",
        "})\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# **Passo 5: Caricare il tokenizer e il modello pre-addestrato**\n",
        "\n",
        "model_name = \"distilbert-base-cased\"  # Modello leggero e case-sensitive\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)  # AutoModelForTokenClassification è il modello pre-addestrato, configurato per il task di token classification (NER).\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_name, num_labels=len(tag2id)\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# **Passo 6: Tokenizzazione e allineamento delle etichette**\n",
        "\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples['token'],\n",
        "        is_split_into_words=True,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=64  # Regola questo valore in base alla lunghezza media delle frasi\n",
        "    )\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples['ner_tag_id']):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        label_ids = []\n",
        "        previous_word_idx = None\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)  # Token speciali\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])  # Token principali\n",
        "            else:\n",
        "                label_ids.append(-100)  # Sotto-token\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "# Applicare la tokenizzazione ai dataset\n",
        "print(\"Tokenizzazione dei dataset in corso...\")\n",
        "tokenized_datasets = datasets.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    remove_columns=['id', 'token', 'ner_tag_id']\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# **Passo 7: Preparare per l'addestramento**\n",
        "\n",
        "# Preparare il data collator\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)  # Data Collator: gestisce il padding dinamico durante la creazione dei batch, in modo che ogni batch sia della stessa lunghezza del token più lungo presente. Questo aumenta l'efficienza e la gestione della memoria.\n",
        "\n",
        "# Definire la funzione per calcolare le metriche\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    true_predictions = [\n",
        "        [id2tag[pred] for (pred, label_id) in zip(prediction, label) if label_id != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [id2tag[label_id] for (pred, label_id) in zip(prediction, label) if label_id != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    # Utilizzare seqeval per calcolare le metriche\n",
        "    seqeval = evaluate.load(\"seqeval\")\n",
        "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results.get(\"overall_precision\", 0.0),\n",
        "        \"recall\": results.get(\"overall_recall\", 0.0),\n",
        "        \"f1\": results.get(\"overall_f1\", 0.0),\n",
        "        \"accuracy\": results.get(\"overall_accuracy\", 0.0),\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# **Passo 8: Impostare i parametri di addestramento**\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=save_directory,  # Usa la tua directory di salvataggio qui\n",
        "    num_train_epochs=3,  # Mantieni invariato il numero di epoche\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\",\n",
        "    fp16=torch.cuda.is_available(),\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# **Passo 9: Creare il trainer**\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],  # TRAINING SET UTILIZZATO QUI\n",
        "    eval_dataset=tokenized_datasets['validation'], # VALIDATION SET UTILIZZATO QUI\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# **Passo 10: Avviare l'addestramento**\n",
        "\n",
        "print(\"Inizio dell'addestramento...\")\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407,
          "referenced_widgets": [
            "5544d84f152647c2b0f7946f240b75fc",
            "a3fec287400d4562af1af91b89bdf0e0",
            "368f08f61d284843a1eefe2338fb7c70",
            "6887f77fdbdf4a35b0c542b5c02b245f",
            "86f6b882500049adbfe1f86bbffd320e",
            "e414f89527634fb8b45669b819f3fa97",
            "95d88877e3804fe2a1c69c83d2ac13b9",
            "52d6d72201e04189943da2fffe4022de",
            "06d56aa960a54a89830fdbfee3a78fc5",
            "099a545b0ee6424f9fce3ab355a2193c",
            "c830868a43a34873a022e2c1b90c318f",
            "868f7cec01e74024bce5fbbd38a1edcc",
            "d10e93e040c34eceb7d656994be5c11c",
            "c9779042eb484859a2fdbe3a1844d507",
            "89b07317607c4224873c15c0fd8fdbdc",
            "dc70f35c0b8b4d15ab38ddc20025523a",
            "fa09777f3b95403ca32dc70eccf1ac85",
            "b76a42fcc3f44da6bfb9fefae7753761",
            "818cad9b12c54ca991f5cd366bf2f098",
            "a6ab131801e04aeda1f9e97472714abe",
            "80e5f7a3855d427ca1153836e896cfd7",
            "268bda9d5c484e8a8dcf919db2e183f5",
            "cf4711960499438fba4b601a1e1bf81e",
            "4fd362f52c23483e986d5dc5527abd1e",
            "3cde5a8b0d8d4654ae7a692457a19252",
            "d59fd3ec62214d8d970e00a4b5e11731",
            "0b1474a958ce4faaa052a82b362ddea5",
            "cf1b2872a96f4288a90d29b704a1acb0",
            "b3cbfd510251430c86400dac75e103f8",
            "b24b1bbb39f548ce87753f1f7602f9ac",
            "5c4fde4b6a7e46baad27ce13ae911059",
            "803b0d60d08a460b84297c891cb3a36d",
            "b9d9ce70f97f4f2299233e8aba07fcd5"
          ]
        },
        "id": "16bYjotv0MMi",
        "outputId": "b3aa7ade-0098-45eb-c591-c8d79bcf89c0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizzazione dei dataset in corso...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2993 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5544d84f152647c2b0f7946f240b75fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/855 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "868f7cec01e74024bce5fbbd38a1edcc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf4711960499438fba4b601a1e1bf81e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizio dell'addestramento...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='282' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [282/282 48:43, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.672800</td>\n",
              "      <td>0.207359</td>\n",
              "      <td>0.802809</td>\n",
              "      <td>0.765399</td>\n",
              "      <td>0.783658</td>\n",
              "      <td>0.930994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.157300</td>\n",
              "      <td>0.136910</td>\n",
              "      <td>0.867406</td>\n",
              "      <td>0.879486</td>\n",
              "      <td>0.873404</td>\n",
              "      <td>0.958503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.078600</td>\n",
              "      <td>0.121626</td>\n",
              "      <td>0.889655</td>\n",
              "      <td>0.898232</td>\n",
              "      <td>0.893923</td>\n",
              "      <td>0.965031</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=282, training_loss=0.23686940365649284, metrics={'train_runtime': 2934.102, 'train_samples_per_second': 3.06, 'train_steps_per_second': 0.096, 'total_flos': 146655030462336.0, 'train_loss': 0.23686940365649284, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Metriche per Epoca durante l'Addestramento:**\n",
        "\n",
        "Nella tabella, possiamo vedere il progresso del modello in termini di perdita (\"loss\") e metriche di valutazione (Precision, Recall, F1, e Accuracy) durante le tre epoche di addestramento. Ogni colonna rappresenta il valore calcolato per una specifica epoca:\n",
        "\n",
        "***Training Loss e Validation Loss:***\n",
        "\n",
        "La Training Loss e la Validation Loss diminuiscono progressivamente per ciascuna epoca. Questo indica che il modello sta migliorando la sua capacità di apprendere i pattern dai dati, riducendo sia l'errore sui dati di training che l'errore sui dati di validazione. Una diminuzione consistente della Validation Loss suggerisce che il modello non sta overfittando, ma sta generalizzando bene su dati non visti.\n",
        "Notiamo che la Validation Loss scende da 0.310100 nella prima epoca a 0.262881 nella terza epoca, suggerendo un miglioramento continuo nella capacità del modello di fare previsioni accurate sui dati di validazione.\n",
        "\n",
        "\n",
        "***Precision, Recall, F1, e Accuracy:***\n",
        "\n",
        "Precision, Recall, e F1 Score sono metriche fondamentali per valutare le performance del modello nel riconoscimento delle entità nominate (NER).\n",
        "\n",
        "Precision: Rappresenta la percentuale di previsioni corrette tra tutte le previsioni fatte. Vediamo che la precision migliora da 0.679 nella prima epoca a 0.722 nella terza epoca.\n",
        "\n",
        "Recall: Indica la percentuale di entità corrette che il modello è stato capace di individuare. Anche il recall aumenta da 0.673 a 0.755, indicando che il modello è stato in grado di riconoscere più entità correttamente man mano che l'addestramento progrediva.\n",
        "\n",
        "F1 Score: La media armonica di precision e recall, che rappresenta un buon compromesso tra le due metriche. Anche l'F1 score aumenta da 0.676 a 0.738.\n",
        "\n",
        "Accuracy: La Accuracy complessiva sale da 0.899 nella prima epoca a 0.918 nella terza epoca, mostrando un incremento costante nell'accuratezza del modello.\n",
        "\n",
        "In generale, possiamo notare che i valori di tutte le metriche migliorano durante le tre epoche, indicando che il modello è stato in grado di apprendere e migliorare efficacemente."
      ],
      "metadata": {
        "id": "gTLt0D02DIi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# **Passo 11: Valutare il modello sui vari set**\n",
        "\n",
        "# Valutare il modello sul set di validazione\n",
        "print(\"Valutazione del modello sul set di validazione in corso...\")\n",
        "validation_metrics = trainer.evaluate(tokenized_datasets['validation'])\n",
        "print(\"Metriche del set di validazione:\")\n",
        "print(validation_metrics)\n",
        "\n",
        "# Valutare il modello sul set di test\n",
        "print(\"Valutazione del modello sul set di test in corso...\")\n",
        "test_metrics = trainer.evaluate(tokenized_datasets['test'])\n",
        "print(\"Metriche del set di test:\")\n",
        "print(test_metrics)\n",
        "\n",
        "\n",
        "\n",
        "# Raccolta delle metriche\n",
        "data = {\n",
        "    \"Set\": [\"Validation\", \"Test\"],\n",
        "    \"Loss\": [validation_metrics['eval_loss'], test_metrics['eval_loss']],\n",
        "    \"Precision\": [validation_metrics.get('eval_precision', 0.0), test_metrics.get('eval_precision', 0.0)],\n",
        "    \"Recall\": [validation_metrics.get('eval_recall', 0.0), test_metrics.get('eval_recall', 0.0)],\n",
        "    \"F1\": [validation_metrics.get('eval_f1', 0.0), test_metrics.get('eval_f1', 0.0)],\n",
        "    \"Accuracy\": [validation_metrics.get('eval_accuracy', 0.0), test_metrics.get('eval_accuracy', 0.0)]\n",
        "}\n",
        "\n",
        "# Creazione di un DataFrame Pandas\n",
        "metrics_df = pd.DataFrame(data)\n",
        "\n",
        "# Stampa della tabella riassuntiva delle metriche\n",
        "print(\"\\nTabella riassuntiva delle metriche per Validation e Test:\")\n",
        "print(metrics_df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# **Passo 12: Salvare il modello addestrato**\n",
        "\n",
        "trainer.save_model(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "\n",
        "\n",
        "# **Passo 13: Funzione per la predizione su una nuova frase**\n",
        "\n",
        "def predict_ner(sentence):\n",
        "    # Tokenizzare la frase\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        return_tensors='pt',\n",
        "        is_split_into_words=False,\n",
        "        truncation=True,\n",
        "        max_length=64  # Assicurarsi che corrisponda a max_length usato in addestramento\n",
        "    )\n",
        "    input_ids = inputs['input_ids']\n",
        "\n",
        "    # Mettere il modello in modalità valutazione\n",
        "    model.eval()\n",
        "\n",
        "    # Ottenere le predizioni\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids)\n",
        "    predictions = torch.argmax(outputs.logits, dim=2)[0].numpy()\n",
        "\n",
        "    # Convertire input_ids in token\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "\n",
        "    # Ricostruire le parole dai sub-token e assegnare le etichette\n",
        "    words = []\n",
        "    labels = []\n",
        "    for idx, (token, pred) in enumerate(zip(tokens, predictions)):\n",
        "        if token in [tokenizer.cls_token, tokenizer.sep_token, tokenizer.pad_token]:\n",
        "            continue  # Ignora token speciali\n",
        "        if token.startswith('##'):\n",
        "            words[-1] += token[2:]\n",
        "        else:\n",
        "            words.append(token)\n",
        "            labels.append(id2tag[pred])\n",
        "\n",
        "    # Stampare le parole e le relative etichette\n",
        "    print(\"\\nPredizione:\")\n",
        "    print(\"Parola\\tEtichetta\")\n",
        "    for word, label in zip(words, labels):\n",
        "        print(f\"{word}\\t{label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "OwDAnCXVAqhe",
        "outputId": "64d5417d-5d9f-4983-924f-ee5636e19ea0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valutazione del modello sul set di validazione in corso...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='41' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 02:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metriche del set di validazione:\n",
            "{'eval_loss': 0.12162584811449051, 'eval_precision': 0.8896551724137931, 'eval_recall': 0.8982324584895555, 'eval_f1': 0.8939232409381662, 'eval_accuracy': 0.9650308893810468, 'eval_runtime': 95.1234, 'eval_samples_per_second': 8.988, 'eval_steps_per_second': 0.284, 'epoch': 3.0}\n",
            "Valutazione del modello sul set di test in corso...\n",
            "Metriche del set di test:\n",
            "{'eval_loss': 0.12932206690311432, 'eval_precision': 0.8754134509371555, 'eval_recall': 0.8861607142857143, 'eval_f1': 0.8807542983915697, 'eval_accuracy': 0.962435837610826, 'eval_runtime': 39.7975, 'eval_samples_per_second': 10.754, 'eval_steps_per_second': 0.352, 'epoch': 3.0}\n",
            "\n",
            "Tabella riassuntiva delle metriche per Validation e Test:\n",
            "          Set      Loss  Precision    Recall        F1  Accuracy\n",
            "0  Validation  0.121626   0.889655  0.898232  0.893923  0.965031\n",
            "1        Test  0.129322   0.875413  0.886161  0.880754  0.962436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Definisci il percorso di salvataggio nel tuo Google Drive\n",
        "save_directory = '/content/drive/MyDrive/Assignment'\n",
        "\n",
        "# Crea la directory se non esiste già\n",
        "if not os.path.exists(save_directory):\n",
        "    os.makedirs(save_directory)\n",
        "\n",
        "# Salva il modello addestrato\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "print(f\"Modello e tokenizer salvati correttamente nella directory: {save_directory}\")\n",
        "\n",
        "# Non è necessario comprimere e spostare il file, poiché è già nel tuo Google Drive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49RQMvvevzUk",
        "outputId": "f4fbea6d-7cea-4045-99f8-971e78ffcd8c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Modello e tokenizer salvati correttamente nella directory: /content/drive/MyDrive/Assignment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tabella Riassuntiva delle Metriche per Validation e Test**\n",
        "\n",
        "Nella tabella, vengono rappresentate delle metriche calcolate sui set di validazione e di test, dopo il completamento delle tre epoche di addestramento. Questo tipo di analisi aiuta a comprendere le prestazioni del modello su dati non visti, e quindi a valutare la sua capacità di generalizzare:\n",
        "\n",
        "***Validation Set:***\n",
        "\n",
        "Le metriche riportate per il set di validazione sono le seguenti:\n",
        "- Loss: 0.262881, che rappresenta la misura dell'errore del modello sul set di validazione.\n",
        "- Precision: 0.722178.\n",
        "- Recall: 0.755444.\n",
        "- F1 Score: 0.738436.\n",
        "- Accuracy: 0.918093.\n",
        "\n",
        "Questi valori suggeriscono che il modello è stato in grado di generalizzare piuttosto bene, con una buona precision e un buon recall.\n",
        "\n",
        "\n",
        "***Test Set:***\n",
        "\n",
        "Le metriche calcolate sul set di test sono:\n",
        "\n",
        "- Loss: 0.278646, leggermente più alta rispetto al validation set, il che è normale poiché i dati di test sono completamente nuovi per il modello.\n",
        "- Precision: 0.740299. Questo valore di precision è più alto rispetto a quello del set di validazione, indicando che il modello sta facendo previsioni accurate su entità anche nei dati di test.\n",
        "- Recall: 0.759571, mostrando che il modello riesce a trovare un buon numero di entità corrette nei dati di test.\n",
        "- F1 Score: 0.749811. Anche l'F1 score è più alto rispetto al set di validazione, suggerendo una buona capacità di compromesso tra precision e recall sui dati di test.\n",
        "- Accuracy: 0.914286, un valore simile a quello del validation set, il che indica che il modello sta generalizzando bene.\n",
        "\n",
        "Interpretazione Complessiva:\n",
        "- In generale, osserviamo che il modello mostra buoni risultati sia sui dati di validazione che di test. L'accuratezza e l'F1 score relativamente alti suggeriscono che il modello ha appreso a riconoscere le entità nominate in maniera affidabile e che il rischio di overfitting è basso.\n",
        "- Il Recall relativamente alto rispetto alla Precision suggerisce che il modello è piuttosto \"inclusivo\", cercando di identificare la maggior parte delle entità, anche se questo significa che occasionalmente potrebbe fare delle previsioni meno precise (ovvero, predire un'entità dove non c'è).\n",
        "- La coerenza tra le metriche di validazione e di test è un buon segnale, indicando che il modello ha una capacità di generalizzazione sufficiente su dati mai visti prima, senza aver appreso pattern troppo specifici del training set."
      ],
      "metadata": {
        "id": "UXac_vjkDkK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict_ner(sentence):\n",
        "    # Tokenizzare la frase ottenendo anche gli offset mapping\n",
        "    inputs = tokenizer.encode_plus(sentence, return_tensors=\"pt\", return_offsets_mapping=True, is_split_into_words=False)\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    offsets = inputs[\"offset_mapping\"][0]\n",
        "\n",
        "    # Ottenere le predizioni dal modello\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids).logits\n",
        "    predictions = torch.argmax(outputs, dim=2)[0].numpy()\n",
        "\n",
        "    # Convertire gli input_ids in token\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "\n",
        "    # Ricostruire le parole dai sub-token\n",
        "    words = []\n",
        "    labels = []\n",
        "    current_word = \"\"\n",
        "    current_label = None\n",
        "    for idx, token in enumerate(tokens):\n",
        "        if token == tokenizer.cls_token or token == tokenizer.sep_token:\n",
        "            continue  # Ignora i token speciali [CLS] e [SEP]\n",
        "        if token.startswith(\"##\"):\n",
        "            current_word += token[2:]  # Aggiungi il sub-token alla parola corrente\n",
        "        else:\n",
        "            if current_word != \"\":\n",
        "                words.append(current_word)\n",
        "                labels.append(current_label)\n",
        "            current_word = token\n",
        "            current_label = id2tag[predictions[idx]]\n",
        "    # Aggiungere l'ultima parola\n",
        "    if current_word != \"\":\n",
        "        words.append(current_word)\n",
        "        labels.append(current_label)\n",
        "\n",
        "    # Stampare le parole e le relative etichette\n",
        "    print(\"Parola\\tEtichetta\")\n",
        "    for word, label in zip(words, labels):\n",
        "        print(f\"{word}\\t{label}\")\n",
        "\n",
        "\n",
        "print(\"\\nEsempio di predizione:\")\n",
        "test_sentence = \"let's see if the predictions of @Plottwisters are correct and look if Emma has done a great job here in milan.\"\n",
        "predict_ner(test_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWmgBiUJ02q3",
        "outputId": "59cc918e-98a0-49ff-da0d-35d18e859d6c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Esempio di predizione:\n",
            "Parola\tEtichetta\n",
            "let\tO\n",
            "'\tO\n",
            "s\tO\n",
            "see\tO\n",
            "if\tO\n",
            "the\tO\n",
            "predictions\tO\n",
            "of\tO\n",
            "@\tB-PER\n",
            "Plottwisters\tB-PER\n",
            "are\tO\n",
            "correct\tO\n",
            "and\tO\n",
            "look\tO\n",
            "if\tO\n",
            "Emma\tB-PER\n",
            "has\tO\n",
            "done\tO\n",
            "a\tO\n",
            "great\tO\n",
            "job\tO\n",
            "here\tO\n",
            "in\tO\n",
            "milan\tB-LOC\n",
            ".\tO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence = \"Hi Emma in Milan, !!! America, Obama, Trump and NATO @Plottwister is predicting pretty well.\"\n",
        "predict_ner(test_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qwSfHgGCgdE",
        "outputId": "60c73412-d586-449c-ff17-085d6b82054b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parola\tEtichetta\n",
            "Hi\tO\n",
            "Emma\tB-PER\n",
            "in\tO\n",
            "Milan\tB-LOC\n",
            ",\tO\n",
            "!\tO\n",
            "!\tO\n",
            "!\tO\n",
            "America\tB-PER\n",
            ",\tO\n",
            "Obama\tB-PER\n",
            ",\tO\n",
            "Trump\tB-PER\n",
            "and\tO\n",
            "NATO\tB-PER\n",
            "@\tB-PER\n",
            "Plottwister\tB-PER\n",
            "is\tO\n",
            "predicting\tO\n",
            "pretty\tO\n",
            "well\tO\n",
            ".\tO\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5544d84f152647c2b0f7946f240b75fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3fec287400d4562af1af91b89bdf0e0",
              "IPY_MODEL_368f08f61d284843a1eefe2338fb7c70",
              "IPY_MODEL_6887f77fdbdf4a35b0c542b5c02b245f"
            ],
            "layout": "IPY_MODEL_86f6b882500049adbfe1f86bbffd320e"
          }
        },
        "a3fec287400d4562af1af91b89bdf0e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e414f89527634fb8b45669b819f3fa97",
            "placeholder": "​",
            "style": "IPY_MODEL_95d88877e3804fe2a1c69c83d2ac13b9",
            "value": "Map: 100%"
          }
        },
        "368f08f61d284843a1eefe2338fb7c70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52d6d72201e04189943da2fffe4022de",
            "max": 2993,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06d56aa960a54a89830fdbfee3a78fc5",
            "value": 2993
          }
        },
        "6887f77fdbdf4a35b0c542b5c02b245f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_099a545b0ee6424f9fce3ab355a2193c",
            "placeholder": "​",
            "style": "IPY_MODEL_c830868a43a34873a022e2c1b90c318f",
            "value": " 2993/2993 [00:00&lt;00:00, 3261.58 examples/s]"
          }
        },
        "86f6b882500049adbfe1f86bbffd320e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e414f89527634fb8b45669b819f3fa97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95d88877e3804fe2a1c69c83d2ac13b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52d6d72201e04189943da2fffe4022de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06d56aa960a54a89830fdbfee3a78fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "099a545b0ee6424f9fce3ab355a2193c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c830868a43a34873a022e2c1b90c318f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "868f7cec01e74024bce5fbbd38a1edcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d10e93e040c34eceb7d656994be5c11c",
              "IPY_MODEL_c9779042eb484859a2fdbe3a1844d507",
              "IPY_MODEL_89b07317607c4224873c15c0fd8fdbdc"
            ],
            "layout": "IPY_MODEL_dc70f35c0b8b4d15ab38ddc20025523a"
          }
        },
        "d10e93e040c34eceb7d656994be5c11c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa09777f3b95403ca32dc70eccf1ac85",
            "placeholder": "​",
            "style": "IPY_MODEL_b76a42fcc3f44da6bfb9fefae7753761",
            "value": "Map: 100%"
          }
        },
        "c9779042eb484859a2fdbe3a1844d507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_818cad9b12c54ca991f5cd366bf2f098",
            "max": 855,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6ab131801e04aeda1f9e97472714abe",
            "value": 855
          }
        },
        "89b07317607c4224873c15c0fd8fdbdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80e5f7a3855d427ca1153836e896cfd7",
            "placeholder": "​",
            "style": "IPY_MODEL_268bda9d5c484e8a8dcf919db2e183f5",
            "value": " 855/855 [00:00&lt;00:00, 2892.23 examples/s]"
          }
        },
        "dc70f35c0b8b4d15ab38ddc20025523a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa09777f3b95403ca32dc70eccf1ac85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b76a42fcc3f44da6bfb9fefae7753761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "818cad9b12c54ca991f5cd366bf2f098": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6ab131801e04aeda1f9e97472714abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80e5f7a3855d427ca1153836e896cfd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "268bda9d5c484e8a8dcf919db2e183f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf4711960499438fba4b601a1e1bf81e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4fd362f52c23483e986d5dc5527abd1e",
              "IPY_MODEL_3cde5a8b0d8d4654ae7a692457a19252",
              "IPY_MODEL_d59fd3ec62214d8d970e00a4b5e11731"
            ],
            "layout": "IPY_MODEL_0b1474a958ce4faaa052a82b362ddea5"
          }
        },
        "4fd362f52c23483e986d5dc5527abd1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf1b2872a96f4288a90d29b704a1acb0",
            "placeholder": "​",
            "style": "IPY_MODEL_b3cbfd510251430c86400dac75e103f8",
            "value": "Map: 100%"
          }
        },
        "3cde5a8b0d8d4654ae7a692457a19252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b24b1bbb39f548ce87753f1f7602f9ac",
            "max": 428,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c4fde4b6a7e46baad27ce13ae911059",
            "value": 428
          }
        },
        "d59fd3ec62214d8d970e00a4b5e11731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_803b0d60d08a460b84297c891cb3a36d",
            "placeholder": "​",
            "style": "IPY_MODEL_b9d9ce70f97f4f2299233e8aba07fcd5",
            "value": " 428/428 [00:00&lt;00:00, 2626.76 examples/s]"
          }
        },
        "0b1474a958ce4faaa052a82b362ddea5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf1b2872a96f4288a90d29b704a1acb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3cbfd510251430c86400dac75e103f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b24b1bbb39f548ce87753f1f7602f9ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c4fde4b6a7e46baad27ce13ae911059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "803b0d60d08a460b84297c891cb3a36d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9d9ce70f97f4f2299233e8aba07fcd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MicheleGiambelli/PlotTwisters-Project/blob/main/Transformer_funzionante_emma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading of required libraries**"
      ],
      "metadata": {
        "id": "A09-g-0QhqxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "!pip install transformers datasets evaluate\n",
        "!pip install transformers datasets evaluate seqeval\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification, pipeline\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from datasets import Dataset, DatasetDict\n",
        "import evaluate\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import spacy\n",
        "from collections import Counter, defaultdict\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import plotly.express as px\n",
        "import networkx as nx\n",
        "from PIL import Image\n",
        "import random\n",
        "from itertools import combinations\n",
        "from scipy.interpolate import make_interp_spline\n",
        "from numpy.random import seed\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "M2OQAw6jtPOJ",
        "outputId": "995045fb-0b51-45ac-834a-251ff2fd6ee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets, evaluate\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 evaluate-0.4.3 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.5.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=bd8ac19e34bf023ab58641f832384d47c4d64c66be0ff93babfe4c79851f61a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading data**"
      ],
      "metadata": {
        "id": "kbzqTRkfq7Fh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following are read text rows containing tokens and NER tags, assigning a unique ID to each sentence. We remove empty or invalid rows, concatenating the data into a single clean DataFrame and convert IDs to integers, preparing the dataset for later processing."
      ],
      "metadata": {
        "id": "_ayMu4ZaijEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def file_to_dataframe(file_path):\n",
        "    data = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()  # Leggi tutte le righe del file\n",
        "        for i, line in enumerate(lines):\n",
        "            line = line.strip()  # Rimuove spazi e newline extra\n",
        "            if not line:  # Linea vuota, segna come fine frase\n",
        "                data.append((\"end\", \"end\"))\n",
        "                continue\n",
        "\n",
        "            # Controlla se la riga contiene '\\t' per separare token e tag\n",
        "            if '\\t' in line:\n",
        "                parts = line.split('\\t')\n",
        "                if len(parts) == 2:  # La riga è valida con 2 parti\n",
        "                    token, ner_tag = parts\n",
        "                    data.append((token, ner_tag))\n",
        "                else:  # Riga malformata\n",
        "                    print(f\"Riga malformata alla linea {i + 1}: {line}\")\n",
        "            else:  # Riga senza '\\t'\n",
        "                print(f\"Riga senza tabulazione alla linea {i + 1}: {line}\")\n",
        "                # data.append((\"end\", \"end\"))\n",
        "\n",
        "    return pd.DataFrame(data, columns=['token', 'ner_tag'])\n",
        "\n",
        "# Converte entrambi i file in DataFrame\n",
        "df1 = file_to_dataframe('sample_data/file5.txt')\n",
        "df2 = file_to_dataframe('sample_data/file5.txt')\n",
        "\n",
        "\n",
        "#Assegna id di frase a file6\n",
        "sentence_id = 0\n",
        "for idx, row in df1.iterrows():\n",
        "  df1.loc[idx, 'id'] = sentence_id\n",
        "  if row['token'] == 'end' and row[\"ner_tag\"]==\"end\":\n",
        "    sentence_id += 1\n",
        "\n",
        "for idx, row in df2.iterrows():\n",
        "  df2.loc[idx, 'id'] = sentence_id\n",
        "  if row['token'] == 'end' and row[\"ner_tag\"]==\"end\":\n",
        "    sentence_id += 1\n",
        "\n",
        "\n",
        "df1 = df1[df1[\"ner_tag\"] != \"end\"]\n",
        "df2 = df2[df2[\"ner_tag\"] != \"end\"]\n",
        "\n",
        "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "# Convertire la colonna id da float a int\n",
        "combined_df['id'] = combined_df['id'].astype(int)\n",
        "\n",
        "\n",
        "combined_df = combined_df.dropna(subset=['token']).reset_index(drop=True) # con questo medodo possiamo rimuovere le righe del dataframe il cui valore è mancante\n",
        "\n",
        "# Verifichiamo la presenza di righe vuote (serve più avanti per un problema al codice altrimenti)\n",
        "invalid_tokens = combined_df[~combined_df['token'].apply(lambda x: isinstance(x, str))]\n",
        "\n",
        "# Eliminare le righe con valori non stringa nella colonna 'token'\n",
        "combined_df = combined_df[combined_df['token'].apply(lambda x: isinstance(x, str))].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "kVwwBzpcxTbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used ***SpaCy*** with the pre-trained *en_core_web_sm* template to identify and remove stopwords and punctuation (except @) from the dataset. We implemented a function to clean tokens, remove empty rows, retweets (“rt”) and non-string values."
      ],
      "metadata": {
        "id": "SCoPpSeErds7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuRYwbRmtEds"
      },
      "outputs": [],
      "source": [
        "# Modello di lingua inglese di Spacy\n",
        "nlp = spacy.load('en_core_web_sm')  # en_core_web_sm è un modello pre addestrato di spacy (small model).\n",
        "stopwords = nlp.Defaults.stop_words\n",
        "# Punteggiatura da rimuovere eslusa @\n",
        "punctuation = set(string.punctuation) - {'@'}\n",
        "\n",
        "# Funzione per eliminare stopwords e punteggiatura\n",
        "def remove_stopwords_and_punctuation(df):\n",
        "    df['token_cleaned'] = df['token'].apply(lambda x: x if x.lower() not in stopwords and x not in punctuation else '') # se è un carattere da rimuovere si crea riga vuota\n",
        "    df = df[df['token_cleaned'] != '']  # Rimuove le righe con token vuoti\n",
        "    return df.drop(columns=['token']).rename(columns={'token_cleaned': 'token'}) # si toglie la vecchia colonna \"token\" e si cambia il nome della nuova colonna \"toen_cleaned\" con \"token\"\n",
        "\n",
        "# Applicare la funzione al dataset combinato\n",
        "combined_df = remove_stopwords_and_punctuation(combined_df)\n",
        "\n",
        "# Elimina le righe in cui il token è \"rt\"\n",
        "combined_df = combined_df[combined_df['token'] != 'rt']  # \"rt\" sta per retweet\n",
        "\n",
        "# Reset dell'indice per un DataFrame pulito (siccome prima abbiamo eliminato righe)\n",
        "combined_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Rimuovere eventuali NaN o valori non stringa nella colonna \"token\"\n",
        "combined_df = combined_df.dropna(subset=['token']).reset_index(drop=True)\n",
        "combined_df = combined_df[combined_df['token'].apply(lambda x: isinstance(x, str))].reset_index(drop=True) # manteniamo solo i valori stringa e togliamo il resto"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now divide our *combine_df* into *training* (70%), *test* (10% ) and *validation* (20%) such that *tokens* with the same sentence *id* shall remain in the same order and in the same dataset."
      ],
      "metadata": {
        "id": "4lChJTGJHCGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividere il dataset in train, validation e test\n",
        "unique_ids = combined_df['id'].unique()\n",
        "# seed(42) inutile perchè abbiamo già random_state=42 alla riga sotto\n",
        "shuffled_ids = pd.Series(unique_ids).sample(frac=1, random_state=42).values\n",
        "train_ids, temp_ids = train_test_split(shuffled_ids, test_size=0.3, random_state=42)\n",
        "val_ids, test_ids = train_test_split(temp_ids, test_size=1/3, random_state=42)\n",
        "train_df = combined_df[combined_df['id'].isin(train_ids)]\n",
        "val_df = combined_df[combined_df['id'].isin(val_ids)]\n",
        "test_df = combined_df[combined_df['id'].isin(test_ids)]"
      ],
      "metadata": {
        "id": "Qd8tk6MgG9j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NER-TAG Classification with Transformers**"
      ],
      "metadata": {
        "id": "HsyNcgcXIyCo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We defined a path so that we could save the model later (in case we were not using Google Colab)."
      ],
      "metadata": {
        "id": "2AkUegOzLpg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Per salvataggio modello (codice datato, più avanti lo miglioro, non lo tolgo altrimenti devo fare fine-tuning di nuovo)\n",
        "save_directory = r'C:\\Users\\capel\\OneDrive\\Desktop\\Data Visualization and Text Mining\\Assignment'\n",
        "if not os.path.exists(save_directory):\n",
        "    os.makedirs(save_directory)"
      ],
      "metadata": {
        "id": "lFPjMhvgL0fP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To prevent the occurrence of a request for an authentication API key to wandb we wrote this line of code.     "
      ],
      "metadata": {
        "id": "r3LgCNNFMjut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Disabilitare wandb per evitare richieste di API key\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"   # Disabilitare wandb (Weights and Biases): evita richieste di autenticazione a Weights and Biases, uno strumento di monitoraggio delle esperienze di machine learning.\n"
      ],
      "metadata": {
        "id": "JM5Cm9wMMkOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Mapping NER labels to unique IDs**\n"
      ],
      "metadata": {
        "id": "KD0l2wu7Kqe3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After identifying all unique NER labels in the data we created two map dictionaries:\n",
        "- ***tag2id***: associates each NER label with a unique numeric ID\n",
        "- ***id2tag***: this does the reverse (numeric ID to NER label).\n",
        "Finally, we apply the tag2id mapping to the three datasets thereby replacing the NER labels with their respective numeric IDs to make the data compatible with the *Hugging* *Face* model."
      ],
      "metadata": {
        "id": "8amtA92rNdSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# step 1: Mappare le etichette NER a ID unici\n",
        "all_df = pd.concat([train_df, val_df, test_df])                     # si poteva utilizzare direttamente combined_df\n",
        "unique_tags = all_df['ner_tag'].unique().tolist()                   # .tolist() converte l'array NumPy restituito da .unique() in una lista Python.\n",
        "tag2id = {tag: idx for idx, tag in enumerate(unique_tags)}          # dizionario in cui la chiave è il NER e il valore è un numero\n",
        "id2tag = {idx: tag for tag, idx in tag2id.items()}                  # viceversa\n",
        "train_df['ner_tag_id'] = train_df['ner_tag'].map(tag2id)            # ogni NER viene sostituito dal corrispondente id numerico presente nel dizionario tag2id\n",
        "val_df['ner_tag_id'] = val_df['ner_tag'].map(tag2id)\n",
        "test_df['ner_tag_id'] = test_df['ner_tag'].map(tag2id)"
      ],
      "metadata": {
        "id": "rNr8vmPIG_Y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preparing Data for Hugging Face**"
      ],
      "metadata": {
        "id": "9bkfYrWKOW1w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The multiple datasets are reorganized using Pandas *groupby*. The data are grouped by sentence by ID, aggregating tokens and NER numeric labels into lists. This format is required for Hugging Face, since models like BERT work on sentence-level input. In the end, we get three DataFrames (train, val, test), each with one row per complete sentence and its columns with associated tokens and tags."
      ],
      "metadata": {
        "id": "cLPvg17nMtCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####   *step 2: Preparare i dati per Hugging Face**  ########\n",
        "\n",
        "# Raggruppare i token e le etichette per frase utilizzando 'id' come identificatore siccome  modelli tipo BERT operano su frasi complete.\n",
        "def group_data(df):\n",
        "    return df.groupby('id').agg({'token': list, 'ner_tag_id': list}).reset_index()\n",
        "\n",
        "train_dataset = group_data(train_df)\n",
        "val_dataset = group_data(val_df)\n",
        "test_dataset = group_data(test_df)"
      ],
      "metadata": {
        "id": "1xOqCpwtMtL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ensuring the proper alignment between tokens and labels**"
      ],
      "metadata": {
        "id": "HEMrZ5YROsIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To be on the safe side, we double checked that the previous step was successful i.e., we checked that the number of tokens and NER labels for each phrase in the three datasets are aligned. The function uses *.str.len()* from Pandas to compare the length of the token lists and labels in each row of the DataFrame. If there are mismatches, the problematic sentences will be printed, otherwise the check passes successfully."
      ],
      "metadata": {
        "id": "DlX1NNQTOsTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####   **step 3: Verificare l'allineamento tra token e etichette**   #####\n",
        "\n",
        "def check_token_label_alignment(df_grouped):\n",
        "    misaligned = df_grouped[\n",
        "        df_grouped['token'].str.len() != df_grouped['ner_tag_id'].str.len()\n",
        "    ]\n",
        "    if not misaligned.empty:\n",
        "        print(\"Frasi con disallineamento tra token e etichette:\")\n",
        "        print(misaligned)\n",
        "    return misaligned.empty\n",
        "\n",
        "assert check_token_label_alignment(train_dataset), \"Disallineamento nel train set\"\n",
        "assert check_token_label_alignment(val_dataset), \"Disallineamento nel validation set\"\n",
        "assert check_token_label_alignment(test_dataset), \"Disallineamento nel test set\""
      ],
      "metadata": {
        "id": "ML1qcgvROsdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creating the datasets for Hugging Face**"
      ],
      "metadata": {
        "id": "lCS0h_xkQA85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training, validation, and test datasets are converted from Pandas DataFrame format to Hugging Face's Dataset format using the *Dataset.from_pandas()* function.  Finally, the three datasets are grouped into a DatasetDict object, which organizes the data into a single structure, facilitating access and integration with the Hugging Face API."
      ],
      "metadata": {
        "id": "mOX_0XTBQBEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####    *step 4: Creare i dataset per Hugging Face*    #####\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_dataset)  # siccome hugging face utilizza specifici formati utilizziamo \"Dataset\" per convertire un DataFrame Pandas in un formato compatibile\n",
        "val_dataset = Dataset.from_pandas(val_dataset)\n",
        "test_dataset = Dataset.from_pandas(test_dataset)\n",
        "\n",
        "datasets = DatasetDict({   # raggruppiamo tutto insieme per facilita l'uso delle API di hugging face.\n",
        "    'train': train_dataset,\n",
        "    'validation': val_dataset,\n",
        "    'test': test_dataset\n",
        "})"
      ],
      "metadata": {
        "id": "pOYT8bVRQBOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loading the tokenizer and the pre-trained model**"
      ],
      "metadata": {
        "id": "26irRfyQQrqq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Pre-trained model**: The model selected is “***distilbert-base-cased***,” a lightweight version of BERT (Bidirectional Encoder Representations from Transformers) designed to be faster and less memory-intensive than the full BERT. It is case-sensitive.\n",
        "\n",
        "- **Tokenizer**: The ***AutoTokenizer.from_pretrained()*** function automatically loads the tokenizer associated with the pre-trained template.\n",
        "The tokenizer is responsible for splitting the text into tokens and mapping them to numeric IDs compatible with the template. It also handles the addition of special tokens (e.g., [CLS], [SEP]) and padding/truncation.\n",
        "\n",
        "- **Purpose**: The pre-trained model serves as the base and is adapted (fine-tuned) to the specific data of our NER project.\n",
        "\n",
        "Some additional information on ***distilbert-base-cased*** can be found at the following link:\n",
        "\n",
        " https://huggingface.co/distilbert/distilbert-base-cased\n",
        "\n",
        "\n",
        "Below we cite some of the features of the model.\n",
        "- Distillation loss: the model was trained to return the same probabilities as the BERT base model.\n",
        "- Masked language modeling (MLM): this is part of the original training loss of the BERT base model. When taking a sentence, the model randomly masks 15% of the words in the input then run the entire masked sentence through the model and has to predict the masked words. This is different from traditional recurrent neural networks (RNNs) that usually see the words one after the other, or from autoregressive models like GPT which internally mask the future tokens. It allows the model to learn a bidirectional representation of the sentence.\n",
        "- Cosine embedding loss: the model was also trained to generate hidden states as close as possible as the BERT base model.\n",
        "\n",
        "- Even if the training data used for this model could be characterized as fairly neutral, this model can have biased predictions. It also inherits some of the bias of its teacher model.\n",
        "- DistilBERT pretrained on the same data as BERT, which is BookCorpus, a dataset consisting of 11,038 unpublished books and English Wikipedia (excluding lists, tables and headers).\n",
        "- Small size: DistilBERT has about 40 percent fewer parameters than basic BERT.\n",
        "- Performance: Despite being smaller, DistilBERT maintains about 97% of BERT's performance on several NLP benchmarks.\n",
        "- Advantages:\n",
        "  1. Computational efficiency:Requires less memory and computational resources.\n",
        "  2. Speed: Faster during both training and inference.\n",
        "  3. Suitable for resource-limited environments: Ideal for applications that need lightweight models.\n"
      ],
      "metadata": {
        "id": "_HA89qFKQrwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####  **step 5: Caricare il tokenizer e il modello pre-addestrato**  #######\n",
        "\n",
        "model_name = \"distilbert-base-cased\"                   # Modello leggero e case-sensitive\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)  # AutoModelForTokenClassification è il modello pre-addestrato, configurato per il task di token classification (NER).\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_name, num_labels=len(tag2id)                 # specificare il numero di token unici con num_labels=len(tag2id)\n",
        ")\n"
      ],
      "metadata": {
        "id": "XwYRPv-iQr6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tokenization and label alignment**"
      ],
      "metadata": {
        "id": "y-P3lTrRSGsa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *tokenize_and_align_labels* function tokenizes sequences using the Hugging Face tokenizer, maintaining alignment between generated tokens and NER labels. Main tokens retain their original labels, while special tokens and sub-tokens are ignored by assigning -100. Tokenization includes padding to equalize sequences to a maximum length of 65 tokens. The function is applied to the datasets using *datasets.map()*, removing unnecessary columns and producing training-ready datasets."
      ],
      "metadata": {
        "id": "nFrSNezQSGyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####   **step 6: Tokenizzazione e allineamento delle etichette**   ######\n",
        "\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples['token'],\n",
        "        is_split_into_words=True,  # token già divisi in parole (e non frasi)\n",
        "        truncation=True,           # troncare token che superano la lunghezza massima (non ci dovrebbero essere token da 65 in ogni caso)\n",
        "        padding='max_length',      # ricordarsi: il padding è una tecnica utilizzata per gestire input di lunghezza differente. aggiunge token speciali ([PAD]) alle sequenze più corte per uniformarne la lunghezza.\n",
        "        max_length=65              # Lunghezza massima pari a 65\n",
        "    )\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples['ner_tag_id']):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i) # restituisce None per i token speciali come [PAD], [CLS] e [SEP]\n",
        "                                                            # ogni elemento della lista rappresenta l'indice della parola originale a cui il token appartiene oppure None\n",
        "        label_ids = []\n",
        "        previous_word_idx = None\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:                   # si controlla token speciali tipo [CLS], [SEP] e nel caso gli si assegna un etichetta particolare per ignorarli\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])  # Token principali\n",
        "            else:                                  # Gestisce i sotto-token, cioè i token che appartengono alla stessa parola (per sicurezza)\n",
        "                label_ids.append(-100)             # Sotto-token\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "# Applicare la tokenizzazione ai dataset\n",
        "print(\"Tokenizzazione in corso...\")\n",
        "tokenized_datasets = datasets.map(\n",
        "    tokenize_and_align_labels,                    # è la funzione definita prima\n",
        "    batched=True,                                 # più frasi in contemporanea\n",
        "    remove_columns=['id', 'token', 'ner_tag_id']\n",
        ")\n"
      ],
      "metadata": {
        "id": "0Nsfy7IKSG8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preparing for training**"
      ],
      "metadata": {
        "id": "rXk24Kp8S1Tp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Collator**: Hugging Face's *DataCollatorForTokenClassification* is used to handle dynamic padding during batch creation. This ensures that all sequences in a batch have the same length as the longest token, improving efficiency and memory management. testo in corsivo\n",
        "\n",
        "We also computed some metrics to evaluate model performance. This is done by converting probabilistic model predictions to final labels using *np.argmax*.\n",
        "Excluding tokens with -100 label to focus only on relevant tokens.\n",
        "To compute the metrix we used ***seqeval***  that is specific for NER tasks; the metrixs are:\n",
        "- Precision: Percentage of correct entities among those predicted.\n",
        "- Recall: Percentage of correct entities among those present.\n",
        "- F1-Score: Harmonic mean between precision and recall.\n",
        "- Accuracy: Percentage of tokens classified correctly.\n"
      ],
      "metadata": {
        "id": "Uel6QIMTS1aB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### **step 7: Preparare per l'addestramento**  ######\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)  # Data Collator: gestisce il padding dinamico durante la creazione dei batch, in modo che ogni batch sia della stessa lunghezza del token più lungo presente. Questo aumenta l'efficienza e la gestione della memoria.\n",
        "\n",
        "# Definire la funzione per calcolare le metriche\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p                                    # Rappresenta le predizioni del modello e le etichette vere\n",
        "    predictions = np.argmax(predictions, axis=2)               # Converte le predizioni probabilistiche del modello in etichette finali\n",
        "\n",
        "    true_predictions = [\n",
        "        [id2tag[pred] for (pred, label_id) in zip(prediction, label) if label_id != -100]    # escludiamo i lable -100 ovvero caratteri speciali\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [id2tag[label_id] for (pred, label_id) in zip(prediction, label) if label_id != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    # Sequeval per il calcolo delle metriche\n",
        "    seqeval = evaluate.load(\"seqeval\")                       # SEQUEVAL:  è una libreria Python progettata per calcolare metriche di valutazione per il NER.\n",
        "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results.get(\"overall_precision\", 0.0),  #  Percentuale di entità rilevate correttamente rispetto a tutte quelle predette.\n",
        "        \"recall\": results.get(\"overall_recall\", 0.0),        # Percentuale di entità rilevate correttamente rispetto a tutte quelle effettivamente presenti.\n",
        "        \"f1\": results.get(\"overall_f1\", 0.0),                # Media armonica tra precisione e richiamo\n",
        "        \"accuracy\": results.get(\"overall_accuracy\", 0.0),    # Percentuale di token classificati correttamente (nel validation)\n",
        "\n",
        "    }"
      ],
      "metadata": {
        "id": "Qb5vtZfQS1po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Setting the training parameters**"
      ],
      "metadata": {
        "id": "_u782RGqURnD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We defined the training parameters using ***TrainingArguments*** from Hugging Face. Among them, we specified:\n",
        "\n",
        "- The directory where we want to save the model.\n",
        "- The number of training epochs (3).\n",
        "- The batch size for both training and evaluation.\n",
        "- The evaluation and saving strategy (at each epoch).\n",
        "- The logging every 50 steps to monitor progress.\n",
        "- The automatic loading of the best model at the end of training.\n",
        "- The use of mixed-precision calculations (FP16) if we have a GPU with CUDA support, to optimize performance and memory."
      ],
      "metadata": {
        "id": "HVV3OGhZURrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##    **step 8: Impostare i parametri di addestramento* ######à\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=save_directory,        # Directory in cui vorrei salvare il modello (definita in precedenza)\n",
        "    num_train_epochs=3,               # il modello farà 3 volte il giro del trainig set\n",
        "    per_device_train_batch_size=32,   # numero di campioni processati in parallelo durante l'addestramento e la valutazione.\n",
        "    per_device_eval_batch_size=32,\n",
        "    evaluation_strategy=\"epoch\",      # valutare il modello al termine di ogni epoca\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=50,                # Specifica dove salvare i log e ogni quanti step loggare le informazioni di addestramento (50 dovrebbe essere la prassi)\n",
        "    load_best_model_at_end=True,     # Dopo l'addestramento, carica automaticamente il modello con le migliori prestazioni sulla validation set\n",
        "    report_to=\"none\",\n",
        "    fp16=torch.cuda.is_available(),  # Utilizza calcoli a precisione mista (FP16) se una GPU con supporto CUDA è disponibile, per migliorare la velocità e ridurre il consumo di memoria.\n",
        ")\n"
      ],
      "metadata": {
        "id": "3jrWpouFUR4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creating the trainer**"
      ],
      "metadata": {
        "id": "JhHYYtNqVWlh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We created a trainer using Hugging Face's ***Trainer*** class, which simplifies model training and evaluation. Specifically:\n",
        "\n",
        "- We passed the pre-trained model and previously defined training parameters.\n",
        "- We specified the already tokenized training and validation datasets.\n",
        "- The *tokenizer* and *data_collator* are used to properly handle batch and padding.\n",
        "- The *compute_metrics* function computes evaluation metrics specific to the NER task.\n",
        "- The trainer handles loss automatically, excluding tokens with a -100 label (like padding), making the training process more efficient."
      ],
      "metadata": {
        "id": "qcFuTh71VWsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#####  **step 9: Creare il trainer**  ######\n",
        "\n",
        "trainer = Trainer(                                    # \"Trainer\" in hugging face che include una variante della Cross Entropy Loss la quale ignora automaticamente i token con etichetta -100 (quindi ad esempio i padding)\n",
        "    model=model,                                      # modello pre addestrato\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],        # TRAINING SET UTILIZZATO QUI, ricordarsi che contiene sequenze di stringe e -100\n",
        "    eval_dataset=tokenized_datasets['validation'],    # VALIDATION SET UTILIZZATO QUI\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "NbShktObVW1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Initiating training**"
      ],
      "metadata": {
        "id": "b8rwkbUuV9jl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We started training the model using the ***.train()*** method of the Trainer. This step uses the previously defined parameters, the tokenized datasets, and the pre-trained model. During training, the trainer automatically handles batch splitting, loss calculation and optimization, recording progress and saving the best model at the end of each epoch."
      ],
      "metadata": {
        "id": "HWlCgWqaV9mX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###  step 10: Avviare l'addestramento  ###\n",
        "\n",
        "print(\"Inizio dell'addestramento...\")\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407,
          "referenced_widgets": [
            "5544d84f152647c2b0f7946f240b75fc",
            "a3fec287400d4562af1af91b89bdf0e0",
            "368f08f61d284843a1eefe2338fb7c70",
            "6887f77fdbdf4a35b0c542b5c02b245f",
            "86f6b882500049adbfe1f86bbffd320e",
            "e414f89527634fb8b45669b819f3fa97",
            "95d88877e3804fe2a1c69c83d2ac13b9",
            "52d6d72201e04189943da2fffe4022de",
            "06d56aa960a54a89830fdbfee3a78fc5",
            "099a545b0ee6424f9fce3ab355a2193c",
            "c830868a43a34873a022e2c1b90c318f",
            "868f7cec01e74024bce5fbbd38a1edcc",
            "d10e93e040c34eceb7d656994be5c11c",
            "c9779042eb484859a2fdbe3a1844d507",
            "89b07317607c4224873c15c0fd8fdbdc",
            "dc70f35c0b8b4d15ab38ddc20025523a",
            "fa09777f3b95403ca32dc70eccf1ac85",
            "b76a42fcc3f44da6bfb9fefae7753761",
            "818cad9b12c54ca991f5cd366bf2f098",
            "a6ab131801e04aeda1f9e97472714abe",
            "80e5f7a3855d427ca1153836e896cfd7",
            "268bda9d5c484e8a8dcf919db2e183f5",
            "cf4711960499438fba4b601a1e1bf81e",
            "4fd362f52c23483e986d5dc5527abd1e",
            "3cde5a8b0d8d4654ae7a692457a19252",
            "d59fd3ec62214d8d970e00a4b5e11731",
            "0b1474a958ce4faaa052a82b362ddea5",
            "cf1b2872a96f4288a90d29b704a1acb0",
            "b3cbfd510251430c86400dac75e103f8",
            "b24b1bbb39f548ce87753f1f7602f9ac",
            "5c4fde4b6a7e46baad27ce13ae911059",
            "803b0d60d08a460b84297c891cb3a36d",
            "b9d9ce70f97f4f2299233e8aba07fcd5"
          ]
        },
        "id": "16bYjotv0MMi",
        "outputId": "b3aa7ade-0098-45eb-c591-c8d79bcf89c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizzazione dei dataset in corso...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2993 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5544d84f152647c2b0f7946f240b75fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/855 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "868f7cec01e74024bce5fbbd38a1edcc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf4711960499438fba4b601a1e1bf81e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizio dell'addestramento...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='282' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [282/282 48:43, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.672800</td>\n",
              "      <td>0.207359</td>\n",
              "      <td>0.802809</td>\n",
              "      <td>0.765399</td>\n",
              "      <td>0.783658</td>\n",
              "      <td>0.930994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.157300</td>\n",
              "      <td>0.136910</td>\n",
              "      <td>0.867406</td>\n",
              "      <td>0.879486</td>\n",
              "      <td>0.873404</td>\n",
              "      <td>0.958503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.078600</td>\n",
              "      <td>0.121626</td>\n",
              "      <td>0.889655</td>\n",
              "      <td>0.898232</td>\n",
              "      <td>0.893923</td>\n",
              "      <td>0.965031</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=282, training_loss=0.23686940365649284, metrics={'train_runtime': 2934.102, 'train_samples_per_second': 3.06, 'train_steps_per_second': 0.096, 'total_flos': 146655030462336.0, 'train_loss': 0.23686940365649284, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Metrics by Epoch during Training**:\n",
        "In the table, we can see the progress of the model in terms of loss and evaluation metrics during the three training epochs.\n",
        "\n",
        "1. **Training Loss and Validation Loss**:\n",
        "\n",
        "Training Loss and Validation Loss progressively decrease for each epoch. This indicates that the model is improving its ability to learn patterns from the data, reducing both the error on the training data and the error on the validation data. A consistent decrease in Validation Loss suggests that the model is not overfitting, but is generalizing well on unseen data.\n",
        "\n",
        "2. **Precision, Recall, F1, and Accuracy**:\n",
        "\n",
        "- Precision: Represents the percentage of correct predictions among all predictions made. We see that precision improves from 0.802 in the first epoch to 0.889 in the third epoch.\n",
        "\n",
        "- Recall: It indicates the percentage of correct entities that the model was able to detect. Recall also increases from 0.765 to 0.898, indicating that the model was able to recognize more entities correctly as training progressed.\n",
        "\n",
        "- F1 Score: The harmonic mean of precision and recall, representing a good compromise between the two metrics.\n",
        "\n",
        "- Accuracy: The overall Accuracy goes up showing a steady increase in the accuracy of the model.\n",
        "\n",
        "Overall, we can see that the values of all metrics improve during the three epochs, indicating that the model was able to learn and improve effectively."
      ],
      "metadata": {
        "id": "NiY94rCIXfzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Appraising the model on the various sets**"
      ],
      "metadata": {
        "id": "5ArUW3NpYOfI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We wanted to evaluate the performance of the model on the validation and test datasets using the *.evaluate()* method.\n",
        "\n",
        "In detail:\n",
        "\n",
        "- Evaluation on the validation set: We computed metrics to monitor how the model performs on unseen data during training.\n",
        "- Evaluation on the test set: We computed the final metrics to measure the overall performance of the model.\n",
        "\n",
        "We collected the key metrics (loss, precision, recall, F1-score, and accuracy) and organized them in a Pandas DataFrame for clear visualization. This allows us to easily compare the results between the validation set and the test set."
      ],
      "metadata": {
        "id": "clPmWKkUYOm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### step 11: Valutare il modello sui vari set  ####\n",
        "\n",
        "# Valutare il modello sul set di validazione\n",
        "print(\"Valutazione del modello sul validation set...\")\n",
        "validation_metrics = trainer.evaluate(tokenized_datasets['validation'])\n",
        "print(\"Metriche sul validation set:\")\n",
        "print(validation_metrics)\n",
        "\n",
        "# Valutare il modello sul set di test\n",
        "print(\"Valutazione del modello sul test set...\")\n",
        "test_metrics = trainer.evaluate(tokenized_datasets['test'])\n",
        "print(\"Metriche sul test set:\")\n",
        "print(test_metrics)\n",
        "\n",
        "\n",
        "# Raccolta metriche\n",
        "data = {\n",
        "    \"Set\": [\"Validation\", \"Test\"],\n",
        "    \"Loss\": [validation_metrics['eval_loss'], test_metrics['eval_loss']],\n",
        "    \"Precision\": [validation_metrics.get('eval_precision', 0.0), test_metrics.get('eval_precision', 0.0)],  #0.0 serve per evitare errori nel caso in cui la metrica non sia disponibile\n",
        "    \"Recall\": [validation_metrics.get('eval_recall', 0.0), test_metrics.get('eval_recall', 0.0)],\n",
        "    \"F1\": [validation_metrics.get('eval_f1', 0.0), test_metrics.get('eval_f1', 0.0)],\n",
        "    \"Accuracy\": [validation_metrics.get('eval_accuracy', 0.0), test_metrics.get('eval_accuracy', 0.0)]\n",
        "}\n",
        "\n",
        "# Creazione di un DataFrame Pandas per creare tabella leggibile\n",
        "metrics_df = pd.DataFrame(data)\n",
        "print(\"\\nTabella riassuntiva delle metriche per Validation e Test:\")\n",
        "print(metrics_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "OwDAnCXVAqhe",
        "outputId": "64d5417d-5d9f-4983-924f-ee5636e19ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valutazione del modello sul set di validazione in corso...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='41' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 02:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metriche del set di validazione:\n",
            "{'eval_loss': 0.12162584811449051, 'eval_precision': 0.8896551724137931, 'eval_recall': 0.8982324584895555, 'eval_f1': 0.8939232409381662, 'eval_accuracy': 0.9650308893810468, 'eval_runtime': 95.1234, 'eval_samples_per_second': 8.988, 'eval_steps_per_second': 0.284, 'epoch': 3.0}\n",
            "Valutazione del modello sul set di test in corso...\n",
            "Metriche del set di test:\n",
            "{'eval_loss': 0.12932206690311432, 'eval_precision': 0.8754134509371555, 'eval_recall': 0.8861607142857143, 'eval_f1': 0.8807542983915697, 'eval_accuracy': 0.962435837610826, 'eval_runtime': 39.7975, 'eval_samples_per_second': 10.754, 'eval_steps_per_second': 0.352, 'epoch': 3.0}\n",
            "\n",
            "Tabella riassuntiva delle metriche per Validation e Test:\n",
            "          Set      Loss  Precision    Recall        F1  Accuracy\n",
            "0  Validation  0.121626   0.889655  0.898232  0.893923  0.965031\n",
            "1        Test  0.129322   0.875413  0.886161  0.880754  0.962436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Summary Table of Metrics for Validation and Testing**\n",
        "\n",
        "In the table, metrics calculated on the validation and test sets after the completion of the three training epochs are represented.\n",
        "\n",
        "***Validation Set:*** The values suggest that the model was able to generalize quite well, with good precision and recall.\n",
        "\n",
        "\n",
        "***Test Set:***  Values very similar to validation.\n",
        "\n",
        "\n",
        "Overall Interpretation:\n",
        "- In general, we observe that the model shows good results on both validation and test data. The relatively high accuracy and F1 score suggest that the model has learned to recognize named entities reliably and that the risk of overfitting is low.\n",
        "- The relatively high Recall compared to Precision suggests that the model is rather “inclusive,” trying to identify most entities, although this means that it may occasionally make less accurate predictions (i.e., predict an entity where there is none).\n",
        "- Consistency between validation and test metrics is a good sign, indicating that the model has sufficient generalization ability on data never seen before, without having learned too specific patterns of the training set."
      ],
      "metadata": {
        "id": "UXac_vjkDkK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluation of the non-fine-tuned model**"
      ],
      "metadata": {
        "id": "6nYS99dHddQI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also decided to evaluate the non-fine-tuned model in order to compare the two."
      ],
      "metadata": {
        "id": "-1y7baG0ddzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating the non fine-tuned model on the validation set...\")\n",
        "\n",
        "def tokenize_and_align_labels_non_tuned(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples['token'],\n",
        "        is_split_into_words=True,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=65\n",
        "    )\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples['ner_tag_id']):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        label_ids = []\n",
        "        previous_word_idx = None\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "non_tuned_validation_set = tokenized_datasets['validation'].map(\n",
        "    tokenize_and_align_labels_non_tuned,\n",
        "    batched=True,\n",
        "    remove_columns=['id', 'token', 'ner_tag_id']\n",
        ")\n",
        "\n",
        "non_tuned_results = trainer.evaluate(non_tuned_validation_set)\n",
        "print(\"Non fine-tuned model metrics:\")\n",
        "print(non_tuned_results)\n"
      ],
      "metadata": {
        "id": "pxmiJ4KodeES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "METTERE COMMENTO SULLA PERFORMANCE DI QUESTO E CONFRONTARLA CON L'ALTRO"
      ],
      "metadata": {
        "id": "RHglXL3Jd9h1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GRAFICI PER CONFRONTO TRA I MODELLI**"
      ],
      "metadata": {
        "id": "96fWLV4hgSy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Risultati dei modelli ottenuti da trainer.evaluate()\n",
        "# Supponiamo che questi siano i risultati dei due modelli già calcolati\n",
        "fine_tuned_results = trainer.evaluate(tokenized_datasets['validation'])\n",
        "non_fine_tuned_results = non_tuned_trainer.evaluate(tokenized_datasets['validation'])\n",
        "\n",
        "# Creare un dizionario con le metriche\n",
        "metrics = {\n",
        "    \"Fine-Tuned Model\": {\n",
        "        \"accuracy\": fine_tuned_results['eval_accuracy'],\n",
        "        \"precision\": fine_tuned_results['eval_precision'],\n",
        "        \"recall\": fine_tuned_results['eval_recall'],\n",
        "        \"f1\": fine_tuned_results['eval_f1'],\n",
        "    },\n",
        "    \"Non Fine-Tuned Model\": {\n",
        "        \"accuracy\": non_fine_tuned_results['eval_accuracy'],\n",
        "        \"precision\": non_fine_tuned_results['eval_precision'],\n",
        "        \"recall\": non_fine_tuned_results['eval_recall'],\n",
        "        \"f1\": non_fine_tuned_results['eval_f1'],\n",
        "    }\n",
        "}\n",
        "\n",
        "# Creare un DataFrame per ogni modello\n",
        "metrics_df = pd.DataFrame(metrics)\n",
        "\n",
        "# Generare i grafici per ogni metrica\n",
        "for metric in metrics_df.index:\n",
        "    plt.figure(figsize=(8, 5))\n",
        "\n",
        "    # Valori per il modello fine-tunato\n",
        "    plt.bar(\"Fine-Tuned Model\", metrics_df.loc[metric, \"Fine-Tuned Model\"], label=\"Fine-Tuned\", alpha=0.7)\n",
        "\n",
        "    # Valori per il modello non fine-tunato\n",
        "    plt.bar(\"Non Fine-Tuned Model\", metrics_df.loc[metric, \"Non Fine-Tuned Model\"], label=\"Non Fine-Tuned\", alpha=0.7)\n",
        "\n",
        "    # Dettagli del grafico\n",
        "    plt.title(f\"{metric.capitalize()} Comparison\")\n",
        "    plt.ylabel(metric.capitalize())\n",
        "    plt.ylim(0, 1)\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "CeRN2b--gW29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Saving the model**"
      ],
      "metadata": {
        "id": "2JiZF08aZpyL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we have given the option of saving the model in two different ways depending on whether you use Colab or visual studio code."
      ],
      "metadata": {
        "id": "DvmoWlgEZp_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### **step 12: Salvare il modello addestrato**  ####   questo codice è utile per salvare il modello sul pc se non si sta usando colab\n",
        "\n",
        "trainer.save_model(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "\n",
        "####### SALVARE IL MODELLO  sul drive  #######\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "save_directory = '/content/drive/MyDrive/Assignment'\n",
        "if not os.path.exists(save_directory):\n",
        "    os.makedirs(save_directory)\n",
        "\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "print(f\"Modello e tokenizer salvati correttamente nella directory: {save_directory}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49RQMvvevzUk",
        "outputId": "f4fbea6d-7cea-4045-99f8-971e78ffcd8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Modello e tokenizer salvati correttamente nella directory: /content/drive/MyDrive/Assignment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing the NER label prediction model***\n",
        "\n"
      ],
      "metadata": {
        "id": "fShR92jfeS1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We decided to test the model on ner tag predictions on both the pretrained non-fine-tuned and fine-tuned models.\n",
        "\n",
        "Lets' start with the the pretrained fine-tuned model.  \n",
        "\n",
        "We loaded the fine-tuned model and tokenizer from the ./sample_data directory. The predict_ner function allows us to tokenize a sentence, obtain predictions from the model, and reconstruct words with their respective NER labels, ignoring special tokens. Finally, we tested the model on novel sentences to verify its ability to correctly identify and classify entities such as proper names, places, and organizations."
      ],
      "metadata": {
        "id": "XGoUONhSa1Ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####### TEST DI PREDIZIONE SUL MODELLO FINE TUNATO ###############\n",
        "\n",
        "\n",
        "# Specificare la directory dove sono salvati i file (\"./sample_data\" è la mia ad esmpio)\n",
        "model_directory = \"./sample_data\"\n",
        "\n",
        "# Caricare il modello fine-tunato e il tokenizer\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_directory)  # Carica il modello fine-tunato\n",
        "                                                                          # config: Per configurare il modello.\n",
        "                                                                          # model.safetensors: Per caricare i pesi addestrati.\n",
        "                                                                          # tokenizer_config, special_tokens_map, vocab: Per configurare il tokenizer e mappare i token ai rispettivi ID\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_directory)                # Carica il tokenizer\n",
        "\n",
        "# Funzione di predizione\n",
        "def predict_ner(sentence):\n",
        "    # Tokenizzare la frase\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        return_tensors='pt',             # Restituisce l'output come tensori PyTorch\n",
        "        is_split_into_words=False,       # Input è una frase completa\n",
        "        truncation=True,\n",
        "        max_length=65                    # Lunghezza max usata durante l'addestramento\n",
        "    )\n",
        "    input_ids = inputs['input_ids']\n",
        "\n",
        "    model.eval()                         # Modello in modalità valutazione per evitare modifiche ai pesi\n",
        "\n",
        "    # Ottenere le predizioni\n",
        "    with torch.no_grad():                # Disabilita il calcolo del gradiente\n",
        "        outputs = model(input_ids)       # Si ottengono i logits\n",
        "    predictions = torch.argmax(outputs.logits, dim=2)[0].numpy()    # Per ogni token si seleziona l'indice della classe con la probabilità più alta\n",
        "\n",
        "    # Convertire input_ids in token\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "\n",
        "    # Ricostruire le parole dai sub-token e assegnare le etichette\n",
        "    words = []\n",
        "    labels = []\n",
        "    for idx, (token, pred) in enumerate(zip(tokens, predictions)):\n",
        "        if token in [tokenizer.cls_token, tokenizer.sep_token, tokenizer.pad_token]:\n",
        "            continue\n",
        "        if token.startswith('##'):\n",
        "            words[-1] += token[2:]\n",
        "        else:\n",
        "            words.append(token)\n",
        "            labels.append(id2tag[pred])\n",
        "\n",
        "    # Stampare le parole e le relative etichette\n",
        "    print(\"\\nPredizione:\")\n",
        "    print(\"Parola\\tEtichetta\")\n",
        "    for word, label in zip(words, labels):\n",
        "        print(f\"{word}\\t{label}\")\n",
        "\n",
        "\n",
        "print(\"\\nEsempio di predizione:\")\n",
        "test_sentence = \"let's see if the predictions of @Plottwisters are correct and look if Emma has done a great job here in milan.\"\n",
        "predict_ner(test_sentence)\n",
        "test_sentence = \"Hi Emma in Milan, !!! America, Obama, Trump and NATO @Plottwister is predicting pretty well.\"\n",
        "predict_ner(test_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVShVUrcaREr",
        "outputId": "718b2b40-e9d8-46d9-ce69-b7e386b8f882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Esempio di predizione:\n",
            "\n",
            "Predizione:\n",
            "Parola\tEtichetta\n",
            "let\tO\n",
            "'\tO\n",
            "s\tO\n",
            "see\tO\n",
            "if\tO\n",
            "the\tO\n",
            "predictions\tO\n",
            "of\tO\n",
            "@\tB-PER\n",
            "Plottwisters\tB-PER\n",
            "are\tO\n",
            "correct\tO\n",
            "and\tO\n",
            "look\tO\n",
            "if\tO\n",
            "Emma\tB-PER\n",
            "has\tO\n",
            "done\tO\n",
            "a\tO\n",
            "great\tO\n",
            "job\tO\n",
            "here\tO\n",
            "in\tO\n",
            "milan\tB-LOC\n",
            ".\tO\n",
            "\n",
            "Predizione:\n",
            "Parola\tEtichetta\n",
            "Hi\tO\n",
            "Emma\tB-PER\n",
            "in\tO\n",
            "Milan\tB-LOC\n",
            ",\tO\n",
            "!\tO\n",
            "!\tO\n",
            "!\tO\n",
            "America\tB-PER\n",
            ",\tO\n",
            "Obama\tB-PER\n",
            ",\tO\n",
            "Trump\tB-PER\n",
            "and\tO\n",
            "NATO\tB-PER\n",
            "@\tB-PER\n",
            "Plottwister\tB-PER\n",
            "is\tO\n",
            "predicting\tO\n",
            "pretty\tO\n",
            "well\tO\n",
            ".\tO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then used the same approach for the non-fine-tuned model"
      ],
      "metadata": {
        "id": "CppaA1OBbRCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####  TESTIAMO IL MODELLO  (ma sul modello di hugging face e non sul modello fine-tunato, dopo lo farò pure su quello), è una prova   ########\n",
        "\n",
        "def predict_ner(sentence):\n",
        "    # Tokenizzare la frase (ovvero trasforma ogni parola in un ID numerico.)\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        return_tensors='pt',             # Restituisce l'output come tensori PyTorch\n",
        "        is_split_into_words=False,       # input è una frase cimpleta\n",
        "        truncation=True,\n",
        "        max_length=65                    # lunghezza max usata durante l'addestramento\n",
        "    )\n",
        "    input_ids = inputs['input_ids']\n",
        "\n",
        "\n",
        "    model.eval()                         # modello in modalità valutazione per evitare modifiche dei pesi\n",
        "\n",
        "    # Ottenere le predizioni\n",
        "    with torch.no_grad():                # Disabilita il calcolo del gradiente\n",
        "        outputs = model(input_ids)       # si ottengono i logits che sono le probabilità non normalizzate per ogni token e per ogni classe NER\n",
        "                                         # qua utilizzo il modello addestrato prima\n",
        "    predictions = torch.argmax(outputs.logits, dim=2)[0].numpy()    # Per ogni token si seleziona l'indice della classe con la probabilità più alta\n",
        "\n",
        "    # Convertire input_ids in token\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "\n",
        "    # Ricostruire le parole dai sub-token e assegnare le etichette\n",
        "    words = []\n",
        "    labels = []\n",
        "    for idx, (token, pred) in enumerate(zip(tokens, predictions)):\n",
        "        if token in [tokenizer.cls_token, tokenizer.sep_token, tokenizer.pad_token]:\n",
        "            continue  # Ignora token speciali\n",
        "        if token.startswith('##'):\n",
        "            words[-1] += token[2:]\n",
        "        else:\n",
        "            words.append(token)\n",
        "            labels.append(id2tag[pred])\n",
        "\n",
        "    # Stampare le parole e le relative etichette\n",
        "    print(\"\\nPredizione:\")\n",
        "    print(\"Parola\\tEtichetta\")\n",
        "    for word, label in zip(words, labels):\n",
        "        print(f\"{word}\\t{label}\")"
      ],
      "metadata": {
        "id": "0z3B6Lq6d437"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###  Esempi di predizione   ###\n",
        "print(\"\\nEsempio di predizione:\")\n",
        "test_sentence = \"let's see if the predictions of @Plottwisters are correct and look if Emma has done a great job here in milan.\"\n",
        "predict_ner(test_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWmgBiUJ02q3",
        "outputId": "59cc918e-98a0-49ff-da0d-35d18e859d6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Esempio di predizione:\n",
            "Parola\tEtichetta\n",
            "let\tO\n",
            "'\tO\n",
            "s\tO\n",
            "see\tO\n",
            "if\tO\n",
            "the\tO\n",
            "predictions\tO\n",
            "of\tO\n",
            "@\tB-PER\n",
            "Plottwisters\tB-PER\n",
            "are\tO\n",
            "correct\tO\n",
            "and\tO\n",
            "look\tO\n",
            "if\tO\n",
            "Emma\tB-PER\n",
            "has\tO\n",
            "done\tO\n",
            "a\tO\n",
            "great\tO\n",
            "job\tO\n",
            "here\tO\n",
            "in\tO\n",
            "milan\tB-LOC\n",
            ".\tO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that both models make accurate and precise predictions."
      ],
      "metadata": {
        "id": "A3owti64bZht"
      }
    }
  ]
}
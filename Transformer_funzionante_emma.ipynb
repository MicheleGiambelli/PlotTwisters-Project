{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5544d84f152647c2b0f7946f240b75fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3fec287400d4562af1af91b89bdf0e0",
              "IPY_MODEL_368f08f61d284843a1eefe2338fb7c70",
              "IPY_MODEL_6887f77fdbdf4a35b0c542b5c02b245f"
            ],
            "layout": "IPY_MODEL_86f6b882500049adbfe1f86bbffd320e"
          }
        },
        "a3fec287400d4562af1af91b89bdf0e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e414f89527634fb8b45669b819f3fa97",
            "placeholder": "​",
            "style": "IPY_MODEL_95d88877e3804fe2a1c69c83d2ac13b9",
            "value": "Map: 100%"
          }
        },
        "368f08f61d284843a1eefe2338fb7c70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52d6d72201e04189943da2fffe4022de",
            "max": 2993,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06d56aa960a54a89830fdbfee3a78fc5",
            "value": 2993
          }
        },
        "6887f77fdbdf4a35b0c542b5c02b245f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_099a545b0ee6424f9fce3ab355a2193c",
            "placeholder": "​",
            "style": "IPY_MODEL_c830868a43a34873a022e2c1b90c318f",
            "value": " 2993/2993 [00:00&lt;00:00, 3261.58 examples/s]"
          }
        },
        "86f6b882500049adbfe1f86bbffd320e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e414f89527634fb8b45669b819f3fa97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95d88877e3804fe2a1c69c83d2ac13b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52d6d72201e04189943da2fffe4022de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06d56aa960a54a89830fdbfee3a78fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "099a545b0ee6424f9fce3ab355a2193c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c830868a43a34873a022e2c1b90c318f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "868f7cec01e74024bce5fbbd38a1edcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d10e93e040c34eceb7d656994be5c11c",
              "IPY_MODEL_c9779042eb484859a2fdbe3a1844d507",
              "IPY_MODEL_89b07317607c4224873c15c0fd8fdbdc"
            ],
            "layout": "IPY_MODEL_dc70f35c0b8b4d15ab38ddc20025523a"
          }
        },
        "d10e93e040c34eceb7d656994be5c11c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa09777f3b95403ca32dc70eccf1ac85",
            "placeholder": "​",
            "style": "IPY_MODEL_b76a42fcc3f44da6bfb9fefae7753761",
            "value": "Map: 100%"
          }
        },
        "c9779042eb484859a2fdbe3a1844d507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_818cad9b12c54ca991f5cd366bf2f098",
            "max": 855,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6ab131801e04aeda1f9e97472714abe",
            "value": 855
          }
        },
        "89b07317607c4224873c15c0fd8fdbdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80e5f7a3855d427ca1153836e896cfd7",
            "placeholder": "​",
            "style": "IPY_MODEL_268bda9d5c484e8a8dcf919db2e183f5",
            "value": " 855/855 [00:00&lt;00:00, 2892.23 examples/s]"
          }
        },
        "dc70f35c0b8b4d15ab38ddc20025523a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa09777f3b95403ca32dc70eccf1ac85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b76a42fcc3f44da6bfb9fefae7753761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "818cad9b12c54ca991f5cd366bf2f098": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6ab131801e04aeda1f9e97472714abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80e5f7a3855d427ca1153836e896cfd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "268bda9d5c484e8a8dcf919db2e183f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf4711960499438fba4b601a1e1bf81e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4fd362f52c23483e986d5dc5527abd1e",
              "IPY_MODEL_3cde5a8b0d8d4654ae7a692457a19252",
              "IPY_MODEL_d59fd3ec62214d8d970e00a4b5e11731"
            ],
            "layout": "IPY_MODEL_0b1474a958ce4faaa052a82b362ddea5"
          }
        },
        "4fd362f52c23483e986d5dc5527abd1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf1b2872a96f4288a90d29b704a1acb0",
            "placeholder": "​",
            "style": "IPY_MODEL_b3cbfd510251430c86400dac75e103f8",
            "value": "Map: 100%"
          }
        },
        "3cde5a8b0d8d4654ae7a692457a19252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b24b1bbb39f548ce87753f1f7602f9ac",
            "max": 428,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c4fde4b6a7e46baad27ce13ae911059",
            "value": 428
          }
        },
        "d59fd3ec62214d8d970e00a4b5e11731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_803b0d60d08a460b84297c891cb3a36d",
            "placeholder": "​",
            "style": "IPY_MODEL_b9d9ce70f97f4f2299233e8aba07fcd5",
            "value": " 428/428 [00:00&lt;00:00, 2626.76 examples/s]"
          }
        },
        "0b1474a958ce4faaa052a82b362ddea5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf1b2872a96f4288a90d29b704a1acb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3cbfd510251430c86400dac75e103f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b24b1bbb39f548ce87753f1f7602f9ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c4fde4b6a7e46baad27ce13ae911059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "803b0d60d08a460b84297c891cb3a36d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9d9ce70f97f4f2299233e8aba07fcd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MicheleGiambelli/PlotTwisters-Project/blob/main/Transformer_funzionante_emma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "!pip install transformers datasets evaluate\n",
        "!pip install transformers datasets evaluate seqeval\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification, pipeline\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from datasets import Dataset, DatasetDict\n",
        "import evaluate\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import spacy\n",
        "from collections import Counter, defaultdict\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import plotly.express as px\n",
        "import networkx as nx\n",
        "from PIL import Image\n",
        "import random\n",
        "from itertools import combinations\n",
        "from scipy.interpolate import make_interp_spline\n",
        "from numpy.random import seed\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "M2OQAw6jtPOJ",
        "outputId": "995045fb-0b51-45ac-834a-251ff2fd6ee5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets, evaluate\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 evaluate-0.4.3 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.5.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=bd8ac19e34bf023ab58641f832384d47c4d64c66be0ff93babfe4c79851f61a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Caricamento dati + pulizia dataset**"
      ],
      "metadata": {
        "id": "kbzqTRkfq7Fh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df1 = pd.read_csv('sample_data/file5.txt', header=None, delimiter='\\t', names=['token', 'ner_tag'], skip_blank_lines=False)\n",
        "# df1[\"token\"] = df1[\"token\"].fillna(\"end\")\n",
        "# df1[\"ner_tag\"] = df1[\"ner_tag\"].fillna(\"end\")\n",
        "\n",
        "# df2 = pd.read_csv('sample_data/file6.txt', header=None, delimiter='\\t', names=['token', 'ner_tag'], skip_blank_lines=False)\n",
        "# df2[\"token\"] = df2[\"token\"].fillna(\"end\")\n",
        "# df2[\"ner_tag\"] = df2[\"ner_tag\"].fillna(\"end\")\n",
        "\n",
        "\n",
        "def file_to_dataframe(file_path):\n",
        "    data = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()  # Leggi tutte le righe del file\n",
        "        for i, line in enumerate(lines):\n",
        "            line = line.strip()  # Rimuove spazi e newline extra\n",
        "            if not line:  # Linea vuota, segna come fine frase\n",
        "                data.append((\"end\", \"end\"))\n",
        "                continue\n",
        "\n",
        "            # Controlla se la riga contiene '\\t' per separare token e tag\n",
        "            if '\\t' in line:\n",
        "                parts = line.split('\\t')\n",
        "                if len(parts) == 2:  # La riga è valida con 2 parti\n",
        "                    token, ner_tag = parts\n",
        "                    data.append((token, ner_tag))\n",
        "                else:  # Riga malformata\n",
        "                    print(f\"Riga malformata alla linea {i + 1}: {line}\")\n",
        "            else:  # Riga senza '\\t'\n",
        "                print(f\"Riga senza tabulazione alla linea {i + 1}: {line}\")\n",
        "                # data.append((\"end\", \"end\"))\n",
        "\n",
        "    return pd.DataFrame(data, columns=['token', 'ner_tag'])\n",
        "\n",
        "# Converte entrambi i file in DataFrame\n",
        "df1 = file_to_dataframe('sample_data/file5.txt')\n",
        "df2 = file_to_dataframe('sample_data/file5.txt')\n",
        "\n",
        "\n",
        "#Assegna id di frase a file6\n",
        "sentence_id = 0\n",
        "for idx, row in df1.iterrows():\n",
        "  df1.loc[idx, 'id'] = sentence_id\n",
        "  if row['token'] == 'end' and row[\"ner_tag\"]==\"end\":\n",
        "    sentence_id += 1\n",
        "\n",
        "for idx, row in df2.iterrows():\n",
        "  df2.loc[idx, 'id'] = sentence_id\n",
        "  if row['token'] == 'end' and row[\"ner_tag\"]==\"end\":\n",
        "    sentence_id += 1\n",
        "\n",
        "\n",
        "df1 = df1[df1[\"ner_tag\"] != \"end\"]\n",
        "df2 = df2[df2[\"ner_tag\"] != \"end\"]\n",
        "\n",
        "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "# Convertire la colonna id da float a int\n",
        "combined_df['id'] = combined_df['id'].astype(int)\n",
        "\n",
        "\n",
        "combined_df = combined_df.dropna(subset=['token']).reset_index(drop=True) # con questo medodo possiamo rimuovere le righe del dataframe il cui valore è mancante\n",
        "\n",
        "# Verifichiamo la presenza di righe vuote (serve più avanti per un problema al codice altrimenti)\n",
        "invalid_tokens = combined_df[~combined_df['token'].apply(lambda x: isinstance(x, str))]\n",
        "\n",
        "# Eliminare le righe con valori non stringa nella colonna 'token'\n",
        "combined_df = combined_df[combined_df['token'].apply(lambda x: isinstance(x, str))].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "kVwwBzpcxTbc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Di seguito ho utilizzato la libreria open source *spaCy*, ideale per il Natural Language Processing (NLP). Ha supporto multilingue."
      ],
      "metadata": {
        "id": "SCoPpSeErds7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QuRYwbRmtEds"
      },
      "outputs": [],
      "source": [
        "# Modello di lingua inglese di Spacy\n",
        "nlp = spacy.load('en_core_web_sm')  # en_core_web_sm è un modello pre addestrato di spacy (small model).\n",
        "stopwords = nlp.Defaults.stop_words\n",
        "# Punteggiatura da rimuovere eslusa @\n",
        "punctuation = set(string.punctuation) - {'@'}\n",
        "\n",
        "# Funzione per eliminare stopwords e punteggiatura\n",
        "def remove_stopwords_and_punctuation(df):\n",
        "    df['token_cleaned'] = df['token'].apply(lambda x: x if x.lower() not in stopwords and x not in punctuation else '') # se è un carattere da rimuovere si crea riga vuota\n",
        "    df = df[df['token_cleaned'] != '']  # Rimuove le righe con token vuoti\n",
        "    return df.drop(columns=['token']).rename(columns={'token_cleaned': 'token'}) # si toglie la vecchia colonna \"token\" e si cambia il nome della nuova colonna \"toen_cleaned\" con \"token\"\n",
        "\n",
        "# Applicare la funzione al dataset combinato\n",
        "combined_df = remove_stopwords_and_punctuation(combined_df)\n",
        "\n",
        "# Elimina le righe in cui il token è \"rt\"\n",
        "combined_df = combined_df[combined_df['token'] != 'rt']  # \"rt\" sta per retweet\n",
        "\n",
        "# Reset dell'indice per un DataFrame pulito (siccome prima abbiamo eliminato righe)\n",
        "combined_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Rimuovere eventuali NaN o valori non stringa nella colonna \"token\"\n",
        "combined_df = combined_df.dropna(subset=['token']).reset_index(drop=True)\n",
        "combined_df = combined_df[combined_df['token'].apply(lambda x: isinstance(x, str))].reset_index(drop=True) # manteniamo solo i valori stringa e togliamo il resto\n",
        "\n",
        "# Dividere il dataset in train, validation e test\n",
        "unique_ids = combined_df['id'].unique()\n",
        "# seed(42) inutile perchè abbiamo già random_state=42 alla riga sotto\n",
        "shuffled_ids = pd.Series(unique_ids).sample(frac=1, random_state=42).values\n",
        "train_ids, temp_ids = train_test_split(shuffled_ids, test_size=0.3, random_state=42)\n",
        "val_ids, test_ids = train_test_split(temp_ids, test_size=1/3, random_state=42)\n",
        "train_df = combined_df[combined_df['id'].isin(train_ids)]\n",
        "val_df = combined_df[combined_df['id'].isin(val_ids)]\n",
        "test_df = combined_df[combined_df['id'].isin(test_ids)]\n",
        "\n",
        "# Mappare le etichette NER a ID unici\n",
        "all_df = pd.concat([train_df, val_df, test_df])                     # si poteva utilizzare direttamente combined_df\n",
        "unique_tags = all_df['ner_tag'].unique().tolist()                   # .tolist() converte l'array NumPy restituito da .unique() in una lista Python.\n",
        "tag2id = {tag: idx for idx, tag in enumerate(unique_tags)}          # dizionario in cui la chiave è il NER e il valore è un numero\n",
        "id2tag = {idx: tag for tag, idx in tag2id.items()}                  # viceversa\n",
        "train_df['ner_tag_id'] = train_df['ner_tag'].map(tag2id)            # ogni NER viene sostituito dal corrispondente id numerico presente nel dizionario tag2id\n",
        "val_df['ner_tag_id'] = val_df['ner_tag'].map(tag2id)\n",
        "test_df['ner_tag_id'] = test_df['ner_tag'].map(tag2id)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Distilbert-base-cased***\n",
        "\n",
        "Di seguito ho utilizzato un modello già attestrato chiamato ***distilbert-base-cased***.\n",
        "\n",
        "Cos'è *distilbert-base-cased*:\n",
        "\n",
        "*DistilBERT* è una versione più leggera e veloce di *BERT* (Bidirectional Encoder Representations from Transformers).                                      \n",
        "Creato da *Hugging Face*, *DistilBERT* è stato ottenuto attraverso una tecnica chiamata distillazione del modello, che permette di comprimere un modello più grande (come BERT) in uno più piccolo mantenendo gran parte delle sue prestazioni.                                                                     \n",
        "Il modello distilbert-base-cased è la versione di DistilBERT che distingue tra maiuscole e minuscole (case-sensitive).\n",
        "\n",
        "Caratteristiche principali:\n",
        "\n",
        "                                                                                     \n",
        "1. Dimensioni ridotte: DistilBERT ha circa il 40% in meno di parametri rispetto a BERT base. Questo lo rende più leggero e più veloce da addestrare e inferire.\n",
        "\n",
        "\n",
        "2. Prestazioni:Nonostante sia più piccolo, DistilBERT mantiene circa il 97% delle prestazioni di BERT su diversi benchmark NLP.\n",
        "\n",
        "\n",
        "3. Vantaggi:\n",
        "\n",
        "- Efficienza computazionale: Richiede meno memoria e risorse computazionali.\n",
        "- Velocità: Più veloce sia durante l'addestramento che durante l'inferenza.\n",
        "- Adatto per ambienti con risorse limitate: Ideale per applicazioni che necessitano di modelli leggeri.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Quando utilizzare distilbert-base-cased:\n",
        "\n",
        "Quando hai limitazioni di risorse (RAM, GPU).\n",
        "Se hai bisogno di addestrare o eseguire inferenze rapidamente.\n",
        "Quando il leggero calo di prestazioni rispetto a BERT è accettabile per il tuo caso d'uso.\n",
        "\n",
        "\n",
        "Di seguito metto alcune info del modello presenti al seguente link: https://huggingface.co/distilbert/distilbert-base-cased\n",
        "\n",
        "- Distillation loss: the model was trained to return the same probabilities as the BERT base model.\n",
        "- Masked language modeling (MLM): this is part of the original training loss of the BERT base model. When taking a sentence, the model randomly masks 15% of the words in the input then run the entire masked sentence through the model and has to predict the masked words. This is different from traditional recurrent neural networks (RNNs) that usually see the words one after the other, or from autoregressive models like GPT which internally mask the future tokens. It allows the model to learn a bidirectional representation of the sentence.\n",
        "- Cosine embedding loss: the model was also trained to generate hidden states as close as possible as the BERT base model.\n",
        "\n",
        "- Even if the training data used for this model could be characterized as fairly neutral, this model can have biased predictions. It also inherits some of the bias of its teacher model.\n",
        "- DistilBERT pretrained on the same data as BERT, which is BookCorpus, a dataset consisting of 11,038 unpublished books and English Wikipedia (excluding lists, tables and headers)."
      ],
      "metadata": {
        "id": "tPdeqkMYCohK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Disabilitare wandb per evitare richieste di API key\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"   # Disabilitare wandb (Weights and Biases): evita richieste di autenticazione a Weights and Biases, uno strumento di monitoraggio delle esperienze di machine learning.\n",
        "\n",
        "# Per salvataggio modello (codice datato, più avanti lo miglioro, non lo tolgo altrimenti devo fare fine-tuning di nuovo)\n",
        "save_directory = r'C:\\Users\\capel\\OneDrive\\Desktop\\Data Visualization and Text Mining\\Assignment'\n",
        "if not os.path.exists(save_directory):\n",
        "    os.makedirs(save_directory)\n",
        "\n",
        "\n",
        "\n",
        "####   **step 1: Mappare le etichette NER a ID unici** (fatto in precedenza)  #########\n",
        "\n",
        "\n",
        "####   *step 2: Preparare i dati per Hugging Face**  ########\n",
        "\n",
        "# Raggruppare i token e le etichette per frase utilizzando 'id' come identificatore siccome  modelli tipo BERT operano su frasi complete.\n",
        "def group_data(df):\n",
        "    return df.groupby('id').agg({'token': list, 'ner_tag_id': list}).reset_index()\n",
        "\n",
        "train_dataset = group_data(train_df)\n",
        "val_dataset = group_data(val_df)\n",
        "test_dataset = group_data(test_df)\n",
        "\n",
        "\n",
        "####   **step 3: Verificare l'allineamento tra token e etichette**   #####\n",
        "\n",
        "def check_token_label_alignment(df_grouped):\n",
        "    misaligned = df_grouped[\n",
        "        df_grouped['token'].str.len() != df_grouped['ner_tag_id'].str.len()\n",
        "    ]\n",
        "    if not misaligned.empty:\n",
        "        print(\"Frasi con disallineamento tra token e etichette:\")\n",
        "        print(misaligned)\n",
        "    return misaligned.empty\n",
        "\n",
        "assert check_token_label_alignment(train_dataset), \"Disallineamento nel train set\"\n",
        "assert check_token_label_alignment(val_dataset), \"Disallineamento nel validation set\"\n",
        "assert check_token_label_alignment(test_dataset), \"Disallineamento nel test set\"\n",
        "\n",
        "\n",
        "####    *step 4: Creare i dataset per Hugging Face*    #####\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_dataset)  # siccome hugging face utilizza specifici formati utilizziamo \"Dataset\" per convertire un DataFrame Pandas in un formato compatibile\n",
        "val_dataset = Dataset.from_pandas(val_dataset)\n",
        "test_dataset = Dataset.from_pandas(test_dataset)\n",
        "\n",
        "datasets = DatasetDict({   # raggruppiamo tutto insieme per facilita l'uso delle API di hugging face.\n",
        "    'train': train_dataset,\n",
        "    'validation': val_dataset,\n",
        "    'test': test_dataset\n",
        "})\n",
        "\n",
        "\n",
        "####  **step 5: Caricare il tokenizer e il modello pre-addestrato**  #######\n",
        "\n",
        "model_name = \"distilbert-base-cased\"                   # Modello leggero e case-sensitive\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)  # AutoModelForTokenClassification è il modello pre-addestrato, configurato per il task di token classification (NER).\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_name, num_labels=len(tag2id)                 # specificare il numero di token unici con num_labels=len(tag2id)\n",
        ")\n",
        "\n",
        "\n",
        "####   **step 6: Tokenizzazione e allineamento delle etichette**   ######\n",
        "\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples['token'],\n",
        "        is_split_into_words=True,  # token già divisi in parole (e non frasi)\n",
        "        truncation=True,           # troncare token che superano la lunghezza massima (non ci dovrebbero essere token da 65 in ogni caso)\n",
        "        padding='max_length',      # ricordarsi: il padding è una tecnica utilizzata per gestire input di lunghezza differente. aggiunge token speciali ([PAD]) alle sequenze più corte per uniformarne la lunghezza.\n",
        "        max_length=65              # Lunghezza massima pari a 65\n",
        "    )\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples['ner_tag_id']):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i) # restituisce None per i token speciali come [PAD], [CLS] e [SEP]\n",
        "                                                            # ogni elemento della lista rappresenta l'indice della parola originale a cui il token appartiene oppure None\n",
        "        label_ids = []\n",
        "        previous_word_idx = None\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:                   # si controlla token speciali tipo [CLS], [SEP] e nel caso gli si assegna un etichetta particolare per ignorarli\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])  # Token principali\n",
        "            else:                                  # Gestisce i sotto-token, cioè i token che appartengono alla stessa parola (per sicurezza)\n",
        "                label_ids.append(-100)             # Sotto-token\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "# Applicare la tokenizzazione ai dataset\n",
        "print(\"Tokenizzazione in corso...\")\n",
        "tokenized_datasets = datasets.map(\n",
        "    tokenize_and_align_labels,                    # è la funzione definita prima\n",
        "    batched=True,                                 # più frasi in contemporanea\n",
        "    remove_columns=['id', 'token', 'ner_tag_id']\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### **step 7: Preparare per l'addestramento**  ######\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)  # Data Collator: gestisce il padding dinamico durante la creazione dei batch, in modo che ogni batch sia della stessa lunghezza del token più lungo presente. Questo aumenta l'efficienza e la gestione della memoria.\n",
        "\n",
        "# Definire la funzione per calcolare le metriche\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p                                    # Rappresenta le predizioni del modello e le etichette vere\n",
        "    predictions = np.argmax(predictions, axis=2)               # Converte le predizioni probabilistiche del modello in etichette finali\n",
        "\n",
        "    true_predictions = [\n",
        "        [id2tag[pred] for (pred, label_id) in zip(prediction, label) if label_id != -100]    # escludiamo i lable -100 ovvero caratteri speciali\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [id2tag[label_id] for (pred, label_id) in zip(prediction, label) if label_id != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    # Sequeval per il calcolo delle metriche\n",
        "    seqeval = evaluate.load(\"seqeval\")                       # SEQUEVAL:  è una libreria Python progettata per calcolare metriche di valutazione per il NER.\n",
        "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results.get(\"overall_precision\", 0.0),  #  Percentuale di entità rilevate correttamente rispetto a tutte quelle predette.\n",
        "        \"recall\": results.get(\"overall_recall\", 0.0),        # Percentuale di entità rilevate correttamente rispetto a tutte quelle effettivamente presenti.\n",
        "        \"f1\": results.get(\"overall_f1\", 0.0),                # Media armonica tra precisione e richiamo\n",
        "        \"accuracy\": results.get(\"overall_accuracy\", 0.0),    # Percentuale di token classificati correttamente (nel validation)\n",
        "\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###    **step 8: Impostare i parametri di addestramento* ######à\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=save_directory,        # Directory in cui vorrei salvare il modello (definita in precedenza)\n",
        "    num_train_epochs=3,               # il modello farà 3 volte il giro del trainig set\n",
        "    per_device_train_batch_size=32,   # numero di campioni processati in parallelo durante l'addestramento e la valutazione.\n",
        "    per_device_eval_batch_size=32,\n",
        "    evaluation_strategy=\"epoch\",      # valutare il modello al termine di ogni epoca\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=50,                # Specifica dove salvare i log e ogni quanti step loggare le informazioni di addestramento (50 dovrebbe essere la prassi)\n",
        "    load_best_model_at_end=True,     # Dopo l'addestramento, carica automaticamente il modello con le migliori prestazioni sulla validation set\n",
        "    report_to=\"none\",\n",
        "    fp16=torch.cuda.is_available(),  # Utilizza calcoli a precisione mista (FP16) se una GPU con supporto CUDA è disponibile, per migliorare la velocità e ridurre il consumo di memoria.\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#####  **step 9: Creare il trainer**  ######\n",
        "\n",
        "trainer = Trainer(                                    # \"Trainer\" in hugging face che include una variante della Cross Entropy Loss la quale ignora automaticamente i token con etichetta -100 (quindi ad esempio i padding)\n",
        "    model=model,                                      # modello pre addestrato\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],        # TRAINING SET UTILIZZATO QUI, ricordarsi che contiene sequenze di stringe e -100\n",
        "    eval_dataset=tokenized_datasets['validation'],    # VALIDATION SET UTILIZZATO QUI\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "###  step 10: Avviare l'addestramento  ###\n",
        "\n",
        "print(\"Inizio dell'addestramento...\")\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407,
          "referenced_widgets": [
            "5544d84f152647c2b0f7946f240b75fc",
            "a3fec287400d4562af1af91b89bdf0e0",
            "368f08f61d284843a1eefe2338fb7c70",
            "6887f77fdbdf4a35b0c542b5c02b245f",
            "86f6b882500049adbfe1f86bbffd320e",
            "e414f89527634fb8b45669b819f3fa97",
            "95d88877e3804fe2a1c69c83d2ac13b9",
            "52d6d72201e04189943da2fffe4022de",
            "06d56aa960a54a89830fdbfee3a78fc5",
            "099a545b0ee6424f9fce3ab355a2193c",
            "c830868a43a34873a022e2c1b90c318f",
            "868f7cec01e74024bce5fbbd38a1edcc",
            "d10e93e040c34eceb7d656994be5c11c",
            "c9779042eb484859a2fdbe3a1844d507",
            "89b07317607c4224873c15c0fd8fdbdc",
            "dc70f35c0b8b4d15ab38ddc20025523a",
            "fa09777f3b95403ca32dc70eccf1ac85",
            "b76a42fcc3f44da6bfb9fefae7753761",
            "818cad9b12c54ca991f5cd366bf2f098",
            "a6ab131801e04aeda1f9e97472714abe",
            "80e5f7a3855d427ca1153836e896cfd7",
            "268bda9d5c484e8a8dcf919db2e183f5",
            "cf4711960499438fba4b601a1e1bf81e",
            "4fd362f52c23483e986d5dc5527abd1e",
            "3cde5a8b0d8d4654ae7a692457a19252",
            "d59fd3ec62214d8d970e00a4b5e11731",
            "0b1474a958ce4faaa052a82b362ddea5",
            "cf1b2872a96f4288a90d29b704a1acb0",
            "b3cbfd510251430c86400dac75e103f8",
            "b24b1bbb39f548ce87753f1f7602f9ac",
            "5c4fde4b6a7e46baad27ce13ae911059",
            "803b0d60d08a460b84297c891cb3a36d",
            "b9d9ce70f97f4f2299233e8aba07fcd5"
          ]
        },
        "id": "16bYjotv0MMi",
        "outputId": "b3aa7ade-0098-45eb-c591-c8d79bcf89c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizzazione dei dataset in corso...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2993 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5544d84f152647c2b0f7946f240b75fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/855 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "868f7cec01e74024bce5fbbd38a1edcc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf4711960499438fba4b601a1e1bf81e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizio dell'addestramento...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='282' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [282/282 48:43, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.672800</td>\n",
              "      <td>0.207359</td>\n",
              "      <td>0.802809</td>\n",
              "      <td>0.765399</td>\n",
              "      <td>0.783658</td>\n",
              "      <td>0.930994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.157300</td>\n",
              "      <td>0.136910</td>\n",
              "      <td>0.867406</td>\n",
              "      <td>0.879486</td>\n",
              "      <td>0.873404</td>\n",
              "      <td>0.958503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.078600</td>\n",
              "      <td>0.121626</td>\n",
              "      <td>0.889655</td>\n",
              "      <td>0.898232</td>\n",
              "      <td>0.893923</td>\n",
              "      <td>0.965031</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=282, training_loss=0.23686940365649284, metrics={'train_runtime': 2934.102, 'train_samples_per_second': 3.06, 'train_steps_per_second': 0.096, 'total_flos': 146655030462336.0, 'train_loss': 0.23686940365649284, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Metriche per Epoca durante l'Addestramento:**\n",
        "\n",
        "Nella tabella, possiamo vedere il progresso del modello in termini di perdita (\"loss\") e metriche di valutazione durante le tre epoche di addestramento.\n",
        "\n",
        "***Training Loss e Validation Loss:***\n",
        "\n",
        "La Training Loss e la Validation Loss diminuiscono progressivamente per ciascuna epoca. Questo indica che il modello sta migliorando la sua capacità di apprendere i pattern dai dati, riducendo sia l'errore sui dati di training che l'errore sui dati di validazione. Una diminuzione consistente della Validation Loss suggerisce che il modello non sta overfittando, ma sta generalizzando bene su dati non visti.\n",
        "\n",
        "\n",
        "\n",
        "***Precision, Recall, F1, e Accuracy:***\n",
        "\n",
        "\n",
        "*Precision*: Rappresenta la percentuale di previsioni corrette tra tutte le previsioni fatte. Vediamo che la precision migliora da 0.802 nella prima epoca a 0.889 nella terza epoca.\n",
        "\n",
        "*Recall*: Indica la percentuale di entità corrette che il modello è stato capace di individuare. Anche il recall aumenta da 0.765 a 0.898, indicando che il modello è stato in grado di riconoscere più entità correttamente man mano che l'addestramento progrediva.\n",
        "\n",
        "*F1 Score*: La media armonica di precision e recall, che rappresenta un buon compromesso tra le due metriche.\n",
        "\n",
        "*Accuracy*: La Accuracy complessiva sale mostrando un incremento costante nell'accuratezza del modello.\n",
        "\n",
        "In generale, possiamo notare che i valori di tutte le metriche migliorano durante le tre epoche, indicando che il modello è stato in grado di apprendere e migliorare efficacemente."
      ],
      "metadata": {
        "id": "gTLt0D02DIi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### step 11: Valutare il modello sui vari set  ####\n",
        "\n",
        "# Valutare il modello sul set di validazione\n",
        "print(\"Valutazione del modello sul validation set...\")\n",
        "validation_metrics = trainer.evaluate(tokenized_datasets['validation'])\n",
        "print(\"Metriche sul validation set:\")\n",
        "print(validation_metrics)\n",
        "\n",
        "# Valutare il modello sul set di test\n",
        "print(\"Valutazione del modello sul test set...\")\n",
        "test_metrics = trainer.evaluate(tokenized_datasets['test'])\n",
        "print(\"Metriche sul test set:\")\n",
        "print(test_metrics)\n",
        "\n",
        "\n",
        "# Raccolta metriche\n",
        "data = {\n",
        "    \"Set\": [\"Validation\", \"Test\"],\n",
        "    \"Loss\": [validation_metrics['eval_loss'], test_metrics['eval_loss']],\n",
        "    \"Precision\": [validation_metrics.get('eval_precision', 0.0), test_metrics.get('eval_precision', 0.0)],  #0.0 serve per evitare errori nel caso in cui la metrica non sia disponibile\n",
        "    \"Recall\": [validation_metrics.get('eval_recall', 0.0), test_metrics.get('eval_recall', 0.0)],\n",
        "    \"F1\": [validation_metrics.get('eval_f1', 0.0), test_metrics.get('eval_f1', 0.0)],\n",
        "    \"Accuracy\": [validation_metrics.get('eval_accuracy', 0.0), test_metrics.get('eval_accuracy', 0.0)]\n",
        "}\n",
        "\n",
        "# Creazione di un DataFrame Pandas per creare tabella leggibile\n",
        "metrics_df = pd.DataFrame(data)\n",
        "print(\"\\nTabella riassuntiva delle metriche per Validation e Test:\")\n",
        "print(metrics_df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### **step 12: Salvare il modello addestrato**  ####   questo codice è obsoleto\n",
        "\n",
        "trainer.save_model(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "OwDAnCXVAqhe",
        "outputId": "64d5417d-5d9f-4983-924f-ee5636e19ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valutazione del modello sul set di validazione in corso...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='41' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 02:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metriche del set di validazione:\n",
            "{'eval_loss': 0.12162584811449051, 'eval_precision': 0.8896551724137931, 'eval_recall': 0.8982324584895555, 'eval_f1': 0.8939232409381662, 'eval_accuracy': 0.9650308893810468, 'eval_runtime': 95.1234, 'eval_samples_per_second': 8.988, 'eval_steps_per_second': 0.284, 'epoch': 3.0}\n",
            "Valutazione del modello sul set di test in corso...\n",
            "Metriche del set di test:\n",
            "{'eval_loss': 0.12932206690311432, 'eval_precision': 0.8754134509371555, 'eval_recall': 0.8861607142857143, 'eval_f1': 0.8807542983915697, 'eval_accuracy': 0.962435837610826, 'eval_runtime': 39.7975, 'eval_samples_per_second': 10.754, 'eval_steps_per_second': 0.352, 'epoch': 3.0}\n",
            "\n",
            "Tabella riassuntiva delle metriche per Validation e Test:\n",
            "          Set      Loss  Precision    Recall        F1  Accuracy\n",
            "0  Validation  0.121626   0.889655  0.898232  0.893923  0.965031\n",
            "1        Test  0.129322   0.875413  0.886161  0.880754  0.962436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tabella Riassuntiva delle Metriche per Validation e Test**\n",
        "\n",
        "Nella tabella, vengono rappresentate delle metriche calcolate sui set di validazione e di test, dopo il completamento delle tre epoche di addestramento.\n",
        "\n",
        "***Validation Set:***\n",
        "\n",
        "I valori suggeriscono che il modello è stato in grado di generalizzare piuttosto bene, con una buona precision e un buon recall.\n",
        "\n",
        "\n",
        "***Test Set:***\n",
        "Valori molto simili al validation.\n",
        "\n",
        "\n",
        "Interpretazione Complessiva:\n",
        "- In generale, osserviamo che il modello mostra buoni risultati sia sui dati di validazione che di test. L'accuratezza e l'F1 score relativamente alti suggeriscono che il modello ha appreso a riconoscere le entità nominate in maniera affidabile e che il rischio di overfitting è basso.\n",
        "- Il Recall relativamente alto rispetto alla Precision suggerisce che il modello è piuttosto \"inclusivo\", cercando di identificare la maggior parte delle entità, anche se questo significa che occasionalmente potrebbe fare delle previsioni meno precise (ovvero, predire un'entità dove non c'è).\n",
        "- La coerenza tra le metriche di validazione e di test è un buon segnale, indicando che il modello ha una capacità di generalizzazione sufficiente su dati mai visti prima, senza aver appreso pattern troppo specifici del training set."
      ],
      "metadata": {
        "id": "UXac_vjkDkK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####### SALVARE IL MODELLO  sul drive  #######\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "save_directory = '/content/drive/MyDrive/Assignment'\n",
        "if not os.path.exists(save_directory):\n",
        "    os.makedirs(save_directory)\n",
        "\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "print(f\"Modello e tokenizer salvati correttamente nella directory: {save_directory}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49RQMvvevzUk",
        "outputId": "f4fbea6d-7cea-4045-99f8-971e78ffcd8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Modello e tokenizer salvati correttamente nella directory: /content/drive/MyDrive/Assignment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testare il modello di predizione delle etichette NER**\n",
        "\n",
        "Di seguito lo testo sia sul modello non fine-tunato sia su quello fine-tunato."
      ],
      "metadata": {
        "id": "fShR92jfeS1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####  TESTIAMO IL MODELLO  (ma sul modello di hugging face e non sul modello fine-tunato, dopo lo farò pure su quello), è una prova   ########\n",
        "\n",
        "def predict_ner(sentence):\n",
        "    # Tokenizzare la frase (ovvero trasforma ogni parola in un ID numerico.)\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        return_tensors='pt',             # Restituisce l'output come tensori PyTorch\n",
        "        is_split_into_words=False,       # input è una frase cimpleta\n",
        "        truncation=True,\n",
        "        max_length=65                    # lunghezza max usata durante l'addestramento\n",
        "    )\n",
        "    input_ids = inputs['input_ids']\n",
        "\n",
        "\n",
        "    model.eval()                         # modello in modalità valutazione per evitare modifiche dei pesi\n",
        "\n",
        "    # Ottenere le predizioni\n",
        "    with torch.no_grad():                # Disabilita il calcolo del gradiente\n",
        "        outputs = model(input_ids)       # si ottengono i logits che sono le probabilità non normalizzate per ogni token e per ogni classe NER\n",
        "                                         # qua utilizzo il modello addestrato prima\n",
        "    predictions = torch.argmax(outputs.logits, dim=2)[0].numpy()    # Per ogni token si seleziona l'indice della classe con la probabilità più alta\n",
        "\n",
        "    # Convertire input_ids in token\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "\n",
        "    # Ricostruire le parole dai sub-token e assegnare le etichette\n",
        "    words = []\n",
        "    labels = []\n",
        "    for idx, (token, pred) in enumerate(zip(tokens, predictions)):\n",
        "        if token in [tokenizer.cls_token, tokenizer.sep_token, tokenizer.pad_token]:\n",
        "            continue  # Ignora token speciali\n",
        "        if token.startswith('##'):\n",
        "            words[-1] += token[2:]\n",
        "        else:\n",
        "            words.append(token)\n",
        "            labels.append(id2tag[pred])\n",
        "\n",
        "    # Stampare le parole e le relative etichette\n",
        "    print(\"\\nPredizione:\")\n",
        "    print(\"Parola\\tEtichetta\")\n",
        "    for word, label in zip(words, labels):\n",
        "        print(f\"{word}\\t{label}\")"
      ],
      "metadata": {
        "id": "0z3B6Lq6d437"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###  Esempi di predizione   ###\n",
        "print(\"\\nEsempio di predizione:\")\n",
        "test_sentence = \"let's see if the predictions of @Plottwisters are correct and look if Emma has done a great job here in milan.\"\n",
        "predict_ner(test_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWmgBiUJ02q3",
        "outputId": "59cc918e-98a0-49ff-da0d-35d18e859d6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Esempio di predizione:\n",
            "Parola\tEtichetta\n",
            "let\tO\n",
            "'\tO\n",
            "s\tO\n",
            "see\tO\n",
            "if\tO\n",
            "the\tO\n",
            "predictions\tO\n",
            "of\tO\n",
            "@\tB-PER\n",
            "Plottwisters\tB-PER\n",
            "are\tO\n",
            "correct\tO\n",
            "and\tO\n",
            "look\tO\n",
            "if\tO\n",
            "Emma\tB-PER\n",
            "has\tO\n",
            "done\tO\n",
            "a\tO\n",
            "great\tO\n",
            "job\tO\n",
            "here\tO\n",
            "in\tO\n",
            "milan\tB-LOC\n",
            ".\tO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence = \"Hi Emma in Milan, !!! America, Obama, Trump and NATO @Plottwister is predicting pretty well.\"\n",
        "predict_ner(test_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qwSfHgGCgdE",
        "outputId": "ef8f277e-e5b0-4324-ac16-2c3f4b1c8854"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predizione:\n",
            "Parola\tEtichetta\n",
            "Hi\tO\n",
            "Emma\tB-PER\n",
            "in\tO\n",
            "Milan\tB-LOC\n",
            ",\tO\n",
            "!\tO\n",
            "!\tO\n",
            "!\tO\n",
            "America\tB-PER\n",
            ",\tO\n",
            "Obama\tB-PER\n",
            ",\tO\n",
            "Trump\tB-PER\n",
            "and\tO\n",
            "NATO\tB-PER\n",
            "@\tB-PER\n",
            "Plottwister\tB-PER\n",
            "is\tO\n",
            "predicting\tO\n",
            "pretty\tO\n",
            "well\tO\n",
            ".\tO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####### TEST DI PREDIZIONE SUL MODELLO FINE TUNATO ###############\n",
        "\n",
        "\n",
        "# Specificare la directory dove sono salvati i file (\"./sample_data\" è la mia ad esmpio)\n",
        "model_directory = \"./sample_data\"\n",
        "\n",
        "# Caricare il modello fine-tunato e il tokenizer\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_directory)  # Carica il modello fine-tunato\n",
        "                                                                          # config: Per configurare il modello.\n",
        "                                                                          # model.safetensors: Per caricare i pesi addestrati.\n",
        "                                                                          # tokenizer_config, special_tokens_map, vocab: Per configurare il tokenizer e mappare i token ai rispettivi ID\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_directory)                # Carica il tokenizer\n",
        "\n",
        "# Funzione di predizione\n",
        "def predict_ner(sentence):\n",
        "    # Tokenizzare la frase\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        return_tensors='pt',             # Restituisce l'output come tensori PyTorch\n",
        "        is_split_into_words=False,       # Input è una frase completa\n",
        "        truncation=True,\n",
        "        max_length=65                    # Lunghezza max usata durante l'addestramento\n",
        "    )\n",
        "    input_ids = inputs['input_ids']\n",
        "\n",
        "    model.eval()                         # Modello in modalità valutazione per evitare modifiche ai pesi\n",
        "\n",
        "    # Ottenere le predizioni\n",
        "    with torch.no_grad():                # Disabilita il calcolo del gradiente\n",
        "        outputs = model(input_ids)       # Si ottengono i logits\n",
        "    predictions = torch.argmax(outputs.logits, dim=2)[0].numpy()    # Per ogni token si seleziona l'indice della classe con la probabilità più alta\n",
        "\n",
        "    # Convertire input_ids in token\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "\n",
        "    # Ricostruire le parole dai sub-token e assegnare le etichette\n",
        "    words = []\n",
        "    labels = []\n",
        "    for idx, (token, pred) in enumerate(zip(tokens, predictions)):\n",
        "        if token in [tokenizer.cls_token, tokenizer.sep_token, tokenizer.pad_token]:\n",
        "            continue\n",
        "        if token.startswith('##'):\n",
        "            words[-1] += token[2:]\n",
        "        else:\n",
        "            words.append(token)\n",
        "            labels.append(id2tag[pred])\n",
        "\n",
        "    # Stampare le parole e le relative etichette\n",
        "    print(\"\\nPredizione:\")\n",
        "    print(\"Parola\\tEtichetta\")\n",
        "    for word, label in zip(words, labels):\n",
        "        print(f\"{word}\\t{label}\")\n",
        "\n",
        "\n",
        "print(\"\\nEsempio di predizione:\")\n",
        "test_sentence = \"let's see if the predictions of @Plottwisters are correct and look if Emma has done a great job here in milan.\"\n",
        "predict_ner(test_sentence)\n",
        "test_sentence = \"Hi Emma in Milan, !!! America, Obama, Trump and NATO @Plottwister is predicting pretty well.\"\n",
        "predict_ner(test_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVShVUrcaREr",
        "outputId": "718b2b40-e9d8-46d9-ce69-b7e386b8f882"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Esempio di predizione:\n",
            "\n",
            "Predizione:\n",
            "Parola\tEtichetta\n",
            "let\tO\n",
            "'\tO\n",
            "s\tO\n",
            "see\tO\n",
            "if\tO\n",
            "the\tO\n",
            "predictions\tO\n",
            "of\tO\n",
            "@\tB-PER\n",
            "Plottwisters\tB-PER\n",
            "are\tO\n",
            "correct\tO\n",
            "and\tO\n",
            "look\tO\n",
            "if\tO\n",
            "Emma\tB-PER\n",
            "has\tO\n",
            "done\tO\n",
            "a\tO\n",
            "great\tO\n",
            "job\tO\n",
            "here\tO\n",
            "in\tO\n",
            "milan\tB-LOC\n",
            ".\tO\n",
            "\n",
            "Predizione:\n",
            "Parola\tEtichetta\n",
            "Hi\tO\n",
            "Emma\tB-PER\n",
            "in\tO\n",
            "Milan\tB-LOC\n",
            ",\tO\n",
            "!\tO\n",
            "!\tO\n",
            "!\tO\n",
            "America\tB-PER\n",
            ",\tO\n",
            "Obama\tB-PER\n",
            ",\tO\n",
            "Trump\tB-PER\n",
            "and\tO\n",
            "NATO\tB-PER\n",
            "@\tB-PER\n",
            "Plottwister\tB-PER\n",
            "is\tO\n",
            "predicting\tO\n",
            "pretty\tO\n",
            "well\tO\n",
            ".\tO\n"
          ]
        }
      ]
    }
  ]
}